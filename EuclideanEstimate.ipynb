{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## K-L divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Discretely many importance weights and rewards, maximum likelihood of sample $\\{ (w_i, r_i) \\}$ from $h$ is \n",
    "\\begin{alignat}{2}\n",
    "&\\!\\max_{Q \\succeq 0} &\\qquad& \\sum_n \\log(Q_{w_n, r_n}),\\label{eq:mle}\\\\\n",
    "&\\text{subject to} &  & \\vec{w}^\\top Q \\vec{1} = 1, \\tag{$\\beta$} \\label{eq:mle\n",
    "sumw} \\\\\n",
    "&                  &  & \\vec{1}^\\top Q \\vec{1} = 1. \\tag{$\\gamma$} \\label{eq:m\n",
    "lesum}\n",
    "\\end{alignat}\n",
    "Estimate is $\\hat V(\\pi) = \\vec{w}^\\top \\hat{Q} \\vec{r}$. \n",
    "\n",
    "Dual (ignoring constants) is $$\n",
    "\\begin{aligned}\n",
    "\\sup_{\\beta,\\gamma}& -\\beta - \\gamma + \\sum_{n} \\log\\left(w_n \\beta + \\gamma\\right)\\; \\text{ s.t. } \\; \\forall w,r: w \\beta + \\gamma \\geq 0.\n",
    "\\end{aligned}\n",
    "$$ One dual variable can be eliminated by summing the KKT stationarity conditions and leveraging complementary slackness.  Introducing $\\phi \\succeq 0$ as the (matrix of) dual variables associated with $Q \\succeq 0$: $$\n",
    "\\begin{aligned}\n",
    "\\frac{c_{w_i,r_j}}{q_{w_i,r_j}} &= \\phi{w_i,r_j} + w_i \\beta + \\gamma \\implies n = 0 + \\beta + \\gamma, \\\\\n",
    "\\end{aligned}\n",
    "$$ resulting in the 1-D dual $$\n",
    "\\begin{aligned}\n",
    "\\sup_{\\beta} & \\sum_{n} \\log\\left((w_n - 1) \\beta + n\\right) \\; \\text{ s.t. } \\;\\forall w,r: (w - 1) \\beta + n \\geq 0.\n",
    "\\end{aligned}\n",
    "$$  This can be solved by 1-D bracketed search on the gradient followed by recovery of the primal values.\n",
    "\n",
    "Primary recovery begins with the primal-dual relationship for observed $(w, r)$ pairs: $$\n",
    "\\hat Q_{w,r} = \\sum_n \\frac{\\mathbb{1}_{w=w_n,r=r_n}}{\\beta^* (w_n - 1) + N}.\n",
    "$$  The MLE will sometimes put mass on unobserved importance weights, in which case the distribution over rewards for that importance weight is not determined.  The unobserved mass can be determined by solving the linear feasibility problem $$\n",
    "\\begin{alignat}{2}\n",
    "& &  & w_{\\min} \\hat{q}_{\\min} + w_{\\max} \\hat{q}_{\\max} = 1 - \\sum_n \\frac{w_n}{\\beta^* (w_n - 1) + N}, \\notag \\\\\n",
    "&                  &  & \\hat{q}_{\\min} + \\hat{q}_{\\max} = 1 - \\sum_n \\frac{1}{\\beta^* (w_n - 1) + N}, \\notag \\\\\n",
    "& & & {\\hat{q}_{\\min} \\geq 0, \\hat{q}_{\\max} \\geq 0},\\notag\n",
    "\\end{alignat}\n",
    "$$\n",
    "where $\\hat{q}_{\\min}$ and $\\hat{q}_{\\max}$ are associated with\n",
    "$w_{\\min}$ and $w_{\\max}$ respectively.  For robustness we convert this into a non-negative least squares problem $$\n",
    "\\begin{alignat}{2}\n",
    "&\\!\\min_{q_{\\min} \\geq 0, q_{\\max} \\geq 0} &\\qquad& \\left\\| \\left(\\begin{array}{cc} 1 & 1 \\\\ w_{\\min} & w_{\\max} \\end{array} \\right) \\left(\\begin{array}{c} q_{\\min} \\\\ q_{\\max} \\end{array}\\right) - \\left(\\begin{array}{c} 1 - \\sum_n \\frac{1}{\\beta^* (w_n - 1) + N} \\\\ 1 - \\sum_n \\frac{w_n}{\\beta^* (w_n - 1) + N} \\end{array} \\right) \\right\\|^2. \\notag\n",
    "\\end{alignat}\n",
    "$$\n",
    "When $q_{\\min} + q_{\\max} > 0$, the MLE is actually an interval; the center of this interval is found using $1/2 (r_{\\min} + r_{\\max})$ as the reward for unobserved importance weights.\n",
    "\n",
    "**Using a baseline:** When using a baseline, pass in shifted rewards and then add the correction to the result.  Given reward predictor $\\hat r: \\mathcal{X} \\times A \\to [r_{\\min}, r_{\\max}]$, construct data for the MLE $$\n",
    "\\begin{aligned}\n",
    "(w_n, \\tilde r_n) &\\leftarrow \\left(\\frac{\\pi(a_n|x_n)}{h(a_n|x_n)}, r_n - \\hat\n",
    "r(x_n, a_n) \\right),\n",
    "\\end{aligned}\n",
    "$$ apply the MLE on this data (with modified $\\tilde r_{\\min}$ and $\\tilde r_{\\max}$), and then adjust the result via $$\n",
    "\\begin{aligned}\n",
    "\\hat V^{\\text{(rpmle)}} &= \\hat V^{\\text{(mle)}} + \\sum_n \\sum_a \\pi(a_n|x_n) \\hat r(x_n, a_n).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**With censorship**: Suppose some $r_j = \\varnothing$ implying the reward was exogenously censored, and suppose we want to estimate $$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}\\left[r | r \\neq \\varnothing\\right] = \\frac{\\mathbb{E}\\left[r 1_{r \\neq \\varnothing}\\right]}{\\mathbb{E}\\left[1_{r \\neq \\varnothing}\\right]}.\n",
    "\\end{aligned}\n",
    "$$ One possible estimate is $$\n",
    "\\begin{aligned}\n",
    "\\hat V(\\pi) = \\frac{w^\\top Q (r 1_{r \\neq \\varnothing})}{w^\\top Q 1_{r \\neq \\varnothing}}\n",
    "\\end{aligned}\n",
    "$$ which is straightforward when there is no mass assigned to unobserved importance weights.  When there is mass assigned to unobserved importance weights, the MLE is again an interval and we can choose the center point of the interval as the estimate.\n",
    "\n",
    "In python we represent censored rewards with `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Euclidean Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Assume no duplicates for now (infinitesmal futzing, $c_{w,r} = 0$ or $1$).\n",
    "$$\n",
    "\\begin{alignat}{2}\n",
    "&\\!\\min_{Q \\succeq 0} &\\qquad& \\sum_{n} \\frac{1}{2} \\left(N Q_{w_n,r_n} - 1\\right)^2,\\label{eq:mle}\\\\\n",
    "&\\text{subject to} &  & \\vec{w}^\\top Q \\vec{1} = 1, \\tag{$\\beta$} \\label{eq:mlesumw} \\\\\n",
    "&                  &  & \\vec{1}^\\top Q \\vec{1} = 1. \\tag{$\\gamma$} \\label{eq:mlesum}\n",
    "\\end{alignat}\n",
    "$$\n",
    "Langragian:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(Q, \\beta, \\gamma) &= \\beta  (\\vec{w}^\\top Q \\vec{1} -1) + \\gamma (\\vec{1} Q \\vec{1} - 1) + \\sum_{n} \\frac{1}{2} \\left(N Q_{w_n,r_n} - 1\\right)^2. \\\\\n",
    "&= -\\beta - \\gamma + \\sum_{w,r} \\left( \\left( \\beta w + \\gamma \\right) Q_{w,r} + \\frac{1}{2} c_{w,r} \\left(N Q_{w,r} - 1\\right)^2 \\right). \\\\\n",
    "\\frac{\\partial}{\\partial Q_{w,r}} L(Q, \\beta, \\gamma) &= \\beta w + \\gamma + c_{w,r} N \\left(N Q_{w,r} - 1\\right) \\\\\n",
    "\\end{aligned}\n",
    "$$ Dual will be unbounded unless $\\forall w: \\beta w + \\gamma \\geq 0 \\lor c_{w,r} > 0$.  With infinistemal futzing, this \n",
    "is equivalent to $\\forall w: \\beta w + \\gamma \\geq 0$.  $\\beta w + \\gamma = 0$ can only happen everywhere or at $w = w_{\\min}$ or $w = w_{\\max}$ so we will only potentially place undata on an extreme point.  Continuing $\\ldots$\n",
    "<!---\n",
    "1/2 (n q - 1)^2 + (\\[Gamma] + \\[Beta] w) q \n",
    "Solve[D[%, q] == 0, q] // FullSimplify // Collect[#, n]&\n",
    "%% /. %[[1]] // FullSimplify // Collect[#, n]&\n",
    "--->\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Q^*_{w,r} &= \\max\\left\\{0, \\frac{1}{N} - \\frac{\\beta w + \\gamma}{N^2}\\right\\} & (c_{w,r} = 1). \\\\\n",
    "\\end{aligned}\n",
    "$$ The $\\max\\{0,\\ldots\\}$ is difficult to deal with so ignore that for the purpose of finding (approximate) closed-form expressions for the dual variables.  Continuing $\\ldots$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "g (\\beta, \\gamma) &= \\inf_{Q \\succeq 0} L(Q, \\beta, \\gamma) \\\\\n",
    "&\\geq -\\beta - \\gamma + \\sum_n \\left( \\left( \\beta w_n + \\gamma \\right) \\left(\\frac{1}{N} - \\frac{\\beta w_n + \\gamma}{N^2} \\right) + \\frac{1}{2} \\left(\\frac{\\beta w_n + \\gamma}{N}\\right)^2 \\right) \\\\\n",
    "&= -\\beta - \\gamma + \\sum_n \\left( \\frac{\\beta w_n + \\gamma}{N} - \\frac{(\\beta w_n + \\gamma)^2}{2 N^2} \\right) \\\\\n",
    "&= -\\beta  + \\sum_n \\left( \\frac{\\beta w_n}{N} - \\frac{(\\beta w_n + \\gamma)^2}{2 N^2} \\right) \\\\\n",
    "\\end{aligned}\n",
    "$$ The unconstrained $\\gamma$ optimum is $\\beta \\frac{1}{N} \\sum_n w_n$ but this is infeasible.  Therefore maximizing $\\gamma$ under the constraint is $$\n",
    "\\gamma^* = \\begin{cases} -\\beta w_{\\min} & \\beta > 0 \\\\ -\\beta w_{\\max} & \\beta \\leq 0 \\end{cases} \\doteq -\\beta w_{\\text{sgn}(\\beta)}\n",
    "$$ Substituting we get $$\n",
    "\\begin{aligned}\n",
    "g\\left(\\beta, \\gamma^*(\\beta)\\right) &= -\\beta  + \\sum_n \\left( \\frac{\\beta w_n}{N} - \\frac{\\beta^2 (w_n - w_{\\text{sgn}(\\beta)})^2}{2 N^2} \\right) \\\\\n",
    "&= -\\beta + \\beta \\sum_n \\frac{w_n}{N} - \\beta^2 \\sum_n \\frac{(w_n - w_{\\text{sgn}(\\beta)})^2}{2 N^2} \\\\\n",
    "\\frac{\\partial}{\\partial \\beta} g\\left(\\beta, \\gamma^*(\\beta)\\right) &= -1 + \\sum_n \\frac{w_n}{N} - \\beta \\sum_n \\frac{(w_n - w_{\\text{sgn}(\\beta)})^2}{N^2} \\\\\n",
    "\\beta^* &= \\frac{\\left(\\frac{1}{N} \\sum_n w_n\\right) - 1}{\\sum_n \\frac{(w_n - w_{\\text{sgn}(\\beta)})^2}{N^2}} = \\begin{cases}\n",
    "\\frac{\\left(\\frac{1}{N} \\sum_n w_n\\right) - 1}{\\sum_n \\frac{(w_n - w_{\\min})^2}{N^2}} & \\frac{1}{N} \\sum_n w_n > 1 \\\\\n",
    "\\frac{\\left(\\frac{1}{N} \\sum_n w_n\\right) - 1}{\\sum_n \\frac{(w_n - w_{\\max})^2}{N^2}} & \\frac{1}{N} \\sum_n w_n \\leq 1 \\\\\n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "$$ \n",
    "So (approximately)\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Q^*_{w,r} &=\n",
    "\\begin{cases}\n",
    "\\max\\left\\{0, \\frac{1}{N} - \\frac{1}{N} \\left(\\frac{\\left(\\frac{1}{N} \\sum_n w_n\\right) - 1}{\\sum_n \\frac{(w_n - w_{\\min})^2}{N}}\\right)\\left(w - w_{\\min}\\right)\\right\\} & \\frac{1}{N} \\sum_n w_n > 1 \\\\\n",
    "\\max\\left\\{0, \\frac{1}{N} - \\frac{1}{N} \\left(\\frac{\\left(\\frac{1}{N} \\sum_n w_n\\right) - 1}{\\sum_n \\frac{(w_n - w_{\\max})^2}{N}}\\right)\\left(w - w_{\\max}\\right)\\right\\} & \\frac{1}{N} \\sum_n w_n \\leq 1 \\\\\n",
    "\\end{cases}\n",
    "& (c_{w,r} > 0).\n",
    "\\end{aligned}\n",
    "$$ and the value estimate is $$\n",
    "\\begin{aligned}\n",
    "\\hat V(\\pi) &= \n",
    "\\begin{cases}\n",
    "\\frac{1}{N} \\sum_n w_n r_n \\max\\left\\{0, 1 - \\left(\\frac{\\left(\\frac{1}{N} \\sum_n w_n\\right) - 1}{\\frac{1}{N} \\sum_n (w_n - w_{\\min})^2}\\right)\\left(w_n - w_{\\min}\\right)\\right\\} & \\frac{1}{N} \\sum_n w_n > 1 \\\\\n",
    "\\frac{1}{N} \\sum_n w_n r_n \\max\\left\\{0, 1 - \\left(\\frac{\\left(\\frac{1}{N} \\sum_n w_n\\right) - 1}{\\frac{1}{N} \\sum_n (w_n - w_{\\max})^2}\\right)\\left(w_n - w_{\\max}\\right)\\right\\} & \\frac{1}{N} \\sum_n w_n \\leq 1 \\\\\n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "$$ Note both denominators can be computed given $\\frac{1}{N} \\sum_n w_n$ and $\\frac{1}{N} \\sum_n w_n^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Censorship changes results\n",
    "\n",
    "We learned this the hard way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.17414127154917453,\n",
      " {'betastar': -421.93139841688657,\n",
      "  'num': 159912,\n",
      "  'qex': {0: 2.7755671722026296e-17, 380: 0.0005377660516997341},\n",
      "  'qfunc': <function estimate.<locals>.<lambda> at 0x7f5f3c1f9e18>,\n",
      "  'vmax': 0.276316821372124,\n",
      "  'vmin': 0.07196572172622505})\n",
      "(0.15222508738880963,\n",
      " {'betastar': -708.0158311345647,\n",
      "  'num': 268338,\n",
      "  'qex': {0: 0.0, 380: 0.00022164515295090473},\n",
      "  'qfunc': <function estimate.<locals>.<lambda> at 0x7f5f3c203048>,\n",
      "  'vmax': 0.22764427578168045,\n",
      "  'vmin': 0.07680589899593883})\n"
     ]
    }
   ],
   "source": [
    "data, wmin, wmax, censored = None, None, None, None\n",
    "for data, wmin, wmax, censored in [\n",
    "    # some data where exogenous censorship is discarded\n",
    "   ([ (c, w, r) for c, w, r in [ \n",
    "      (86, -59.999996, 0.0), (44884, -1.0497237, 0.0), (16331, -1.0447762, 0.0), (31257, -1.0344828, 0.0), \n",
    "      (15868, -1.0, 0.0), (41332, 0.0, 0.0), (1958, 0.0, 1.0), (17763, 1.0, 0.0), (1339, 1.0, 1.0), \n",
    "      (30726, 1.0344828, 0.0), (3867, 1.0344828, 1.0), (2034, 1.0447762, 1.0), (16728, 1.0447762, 0.0), \n",
    "      (40629, 1.0497237, 0.0), (3445, 1.0497237, 1.0), (85, 59.999996, 0.0), (6, 59.999996, 1.0), \n",
    "     ]\n",
    "     if w >= 0\n",
    "    ], 0, 380, False),\n",
    "    # same data where exogenous censorship is modeled\n",
    "   ([ (c, -w if w < 0 else w, None if w < 0 else r) for c, w, r in [ \n",
    "      (86, -59.999996, 0.0), (44884, -1.0497237, 0.0), (16331, -1.0447762, 0.0), (31257, -1.0344828, 0.0), \n",
    "      (15868, -1.0, 0.0), (41332, 0.0, 0.0), (1958, 0.0, 1.0), (17763, 1.0, 0.0), (1339, 1.0, 1.0), \n",
    "      (30726, 1.0344828, 0.0), (3867, 1.0344828, 1.0), (2034, 1.0447762, 1.0), (16728, 1.0447762, 0.0), \n",
    "      (40629, 1.0497237, 0.0), (3445, 1.0497237, 1.0), (85, 59.999996, 0.0), (6, 59.999996, 1.0), \n",
    "     ]], 0, 380, True),\n",
    "]:\n",
    "    import MLE.MLE\n",
    "\n",
    "    from pprint import pformat\n",
    "    print(pformat(MLE.MLE.estimate(datagen=lambda: data, \n",
    "                                   wmin=wmin, wmax=wmax, rmin=0, rmax=1, raiseonerr=True, censored=censored)))\n",
    "  \n",
    "del data, wmin, wmax, censored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Comparison with CVX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     4
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# CVXPY (primal) implementation\n",
    "\n",
    "class MLETest:\n",
    "    @staticmethod\n",
    "    def cvxestimate(data, wmin, wmax, rmin, rmax):\n",
    "        import cvxpy as cp\n",
    "        import numpy as np\n",
    "        from collections import defaultdict\n",
    "        \n",
    "        cdict = defaultdict(int)\n",
    "        n = 0\n",
    "        for (ci, wi, ri) in data:\n",
    "            assert ci >= 0\n",
    "            assert wi >= wmin and wi <= wmax\n",
    "            assert ri >= rmin and ri <= rmax\n",
    "            if ci > 0:\n",
    "                cdict[(wi, ri)] += ci\n",
    "            n += ci\n",
    "        assert n >= 1\n",
    "        cdict[(wmin, rmin)] += 0\n",
    "        cdict[(wmin, rmax)] += 0\n",
    "        cdict[(wmax, rmin)] += 0\n",
    "        cdict[(wmax, rmax)] += 0\n",
    "        cdict.default_factory = None\n",
    "        \n",
    "        wvec = np.array(list(set(w for (w, _), _ in cdict.items())))\n",
    "        wmaxvec = np.max(wvec)\n",
    "        rvec = np.array(list(set(r for (_, r), _ in cdict.items())))\n",
    "        C = np.array([ [ cdict.get((w, r), 0)/n for r in rvec ] for w in wvec ])\n",
    "        Q = cp.Variable((len(wvec), len(rvec)))\n",
    "            \n",
    "        prob = cp.Problem(cp.Maximize(cp.sum(cp.multiply(C, cp.log(Q)))), [\n",
    "                                cp.sum(cp.matmul((wvec/wmaxvec).T, Q)) == 1/wmaxvec,\n",
    "                                cp.sum(Q) == 1\n",
    "                          ])\n",
    "        prob.solve(solver='ECOS')\n",
    "            \n",
    "        vhat = 0\n",
    "        for i, wi in enumerate(wvec):\n",
    "            for j, rj in enumerate(rvec):\n",
    "                if cdict.get((wi, rj), 0) > 0:\n",
    "                    vhat += wi * Q.value[i, j] * rj\n",
    "                else:\n",
    "                    vhat += wi * Q.value[i, j] * 0.5 * (rmax - rmin)\n",
    " \n",
    "        from scipy.special import xlogy\n",
    "    \n",
    "        return vhat, { \n",
    "            'qstar': { (wvec[i], rvec[j]): Q.value[i, j] for i in range(len(wvec)) for j in range(len(rvec)) },\n",
    "            'likelihood': np.sum(xlogy(C, Q.value)),\n",
    "            'sumofone': np.sum(Q.value),\n",
    "            'sumofw': np.sum(wvec.dot(Q.value)),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:47<00:00,  7.77s/it]\n"
     ]
    }
   ],
   "source": [
    "def testestimate():\n",
    "    from importlib import reload\n",
    "    from math import ceil\n",
    "    import environments.ControlledRangeVariance\n",
    "    import MLE.MLE\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm as tqdm\n",
    "    import sys\n",
    "\n",
    "    reload(environments.ControlledRangeVariance)\n",
    "    reload(MLE.MLE)\n",
    "\n",
    "    wsupport = [ 0, 2, 20 ]\n",
    "    wmax = wsupport[-1]\n",
    "    env = environments.ControlledRangeVariance.ControlledRangeVariance(seed=45, wsupport=wsupport, expwsq=5)\n",
    "\n",
    "    for ndata in tqdm(map(ceil, np.logspace(1, 7, 14)), file=sys.stderr, total=14):\n",
    "        for i in range(1001):\n",
    "            (truevalue, data) = env.sample(ndata)\n",
    "            vhat, qstar = MLE.MLE.estimate(datagen = lambda: data, wmin=0, wmax=wmax, rmin=0, rmax=1, raiseonerr=True)\n",
    "            cvxvhat, cvxqstar = MLETest.cvxestimate(data, wmin=0, wmax=wmax, rmin=0, rmax=1)\n",
    " \n",
    "            from pprint import pformat\n",
    "            assert np.allclose(vhat, cvxvhat, atol=1e-4), pformat(\n",
    "            {\n",
    "                'data': [(c, w, r) for c, w, r in data if c > 0],\n",
    "                'vhat': vhat,\n",
    "                'cvxvhat': cvxvhat,\n",
    "                'qstar': qstar,\n",
    "                'cvxqstar': cvxqstar,\n",
    "            })\n",
    "                                    \n",
    "testestimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:48<00:00,  7.88s/it]\n"
     ]
    }
   ],
   "source": [
    "def megatestestimate():\n",
    "    from importlib import reload\n",
    "    from math import ceil\n",
    "    import environments.ControlledRangeVariance\n",
    "    import MLE.MLE\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm as tqdm\n",
    "    import sys\n",
    "\n",
    "    reload(environments.ControlledRangeVariance)\n",
    "    reload(MLE.MLE)\n",
    "    \n",
    "    def getenv():\n",
    "        import numpy\n",
    "        wsupport = numpy.geomspace(0.5, 1000, 10)\n",
    "        env = environments.ControlledRangeVariance.ControlledRangeVariance(seed=45, wsupport=wsupport, expwsq=100)\n",
    "        return env, env.getpw(), env.range(), env.expectedwsq()\n",
    "\n",
    "    env = getenv()[0]\n",
    "    wmin, wmax = env.range()\n",
    "    \n",
    "    for ndata in tqdm(map(ceil, np.logspace(1, 7, 14)), file=sys.stderr, total=14):\n",
    "        for i in range(1001):\n",
    "            (truevalue, data) = env.sample(ndata)\n",
    "            vhat, qstar = MLE.MLE.estimate(lambda: data, wmin=wmin, wmax=wmax, rmin=0, rmax=1, raiseonerr=True)\n",
    "            try:\n",
    "                cvxvhat, cvxqstar = MLETest.cvxestimate(data, wmin=wmin, wmax=wmax, rmin=0, rmax=1)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            from pprint import pformat\n",
    "            assert np.allclose(vhat, cvxvhat, atol=1e-4) or not np.isfinite(cvxqstar['likelihood']), pformat(\n",
    "            {\n",
    "                'data': [(c, w, r) for c, w, r in data if c > 0],\n",
    "                'vhat': vhat,\n",
    "                'cvxvhat': cvxvhat,\n",
    "                'qstar': qstar,\n",
    "                'cvxqstar': cvxqstar,\n",
    "            })\n",
    "                                    \n",
    "megatestestimate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "code_folding": [
     0,
     42,
     85,
     92
    ]
   },
   "outputs": [],
   "source": [
    "def produceresults(env, method, minexp=1, maxexp=5, numpts=20, ndataperpt=10000):\n",
    "    from math import ceil\n",
    "    import numpy as np\n",
    "    \n",
    "    wmin, wmax = env.range()\n",
    "\n",
    "    for ndata in map(ceil, np.logspace(minexp, maxexp, numpts)):\n",
    "        estimates=[]\n",
    "        for i in range(1, ndataperpt+1):\n",
    "            (truevalue, data) = env.sample(ndata)\n",
    "            try:\n",
    "                estimate = None\n",
    "                estimate = method(data=data, wmin=wmin, wmax=wmax)\n",
    "                assert np.isfinite(estimate)\n",
    "            except:\n",
    "                print('truevalue was {}'.format(truevalue))\n",
    "                print('data was {}'.format(data))\n",
    "                print('estimate was {}'.format(estimate))\n",
    "                raise\n",
    "            \n",
    "            essden = sum(c*w*w for (c, w, _) in data)\n",
    "            essnum = sum(c*w for (c, w, _) in data)\n",
    "            ess = 0 if essden == 0 else essnum*(essnum/essden)\n",
    "                                                \n",
    "            estimates.append(\n",
    "                ( truevalue,\n",
    "                  truevalue - estimate,\n",
    "                  (truevalue - estimate)**2,\n",
    "                 ess\n",
    "                )  \n",
    "            )\n",
    "            \n",
    "        yield (ndata,\n",
    "                { \n",
    "                    'bias': np.abs(sum(x[1] for x in estimates) / len(estimates)),\n",
    "                    'mse': sum(x[2] for x in estimates) / len(estimates),\n",
    "                    'ess': sum(x[3] for x in estimates) / len(estimates),\n",
    "                },\n",
    "              )\n",
    "        \n",
    "%matplotlib inline\n",
    "\n",
    "class FlassPlot:\n",
    "    @staticmethod\n",
    "    def pic(x, y, label):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.loglog(x, y, label=label)\n",
    "        plt.legend()\n",
    "        \n",
    "    @staticmethod\n",
    "    def forpaper():\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        SMALL_SIZE = 10\n",
    "        MEDIUM_SIZE = 16\n",
    "        BIGGER_SIZE = 20\n",
    "\n",
    "        plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "        plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "        plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "        plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "        plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "        plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "        plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "        \n",
    "    @staticmethod\n",
    "    def axeslabel(xlabel, ylabel):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        \n",
    "    @staticmethod\n",
    "    def title(title):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.title(title)\n",
    "        \n",
    "    @staticmethod\n",
    "    def savefig(filename):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "    \n",
    "class ClippedDR:\n",
    "    @staticmethod\n",
    "    def estimate(data, baseline=0.5, **kwargs):\n",
    "        import numpy as np\n",
    "        n = sum(c for c, _, _ in data)\n",
    "        return baseline if n == 0 else np.clip(sum(c*w*(r-baseline)+c*baseline for c, w, r in data) / n, a_min=0, a_max=1)\n",
    "    \n",
    "class SNIPS:\n",
    "    @staticmethod\n",
    "    def estimate(data, **kwargs):\n",
    "        effn = sum(c*w for c, w, _ in data)\n",
    "        return 0.5 if effn == 0 else sum(c*w*r for c, w, r in data) / effn\n",
    "    \n",
    "class Euclidean:\n",
    "    @staticmethod\n",
    "    def estimate(data, wmin, wmax, **kwargs):\n",
    "        n = sum(c for c, _, _ in data)\n",
    "        barw = sum(c*w for c, w, _ in data) / n\n",
    "        barwsq = sum(c*w*w for c, w, _ in data) / n\n",
    "        barwr = sum(c*w*r for c, w, r in data) / n\n",
    "        barwsqr = sum(c*w*w*r for c, w, r in data) / n\n",
    "        barwsq = sum(c*w*w for c, w, r in data) / n\n",
    "        \n",
    "        data = None # sufficient statistics only (!)\n",
    "\n",
    "        wextreme = wmin if barw > 1 else wmax\n",
    "        denom = barwsq - 2 * wextreme * barw + wextreme * wextreme\n",
    "        factor = (barw - 1) / denom\n",
    "\n",
    "        betastarovern = (barw - 1) / denom\n",
    "        gammastarovern = -betastarovern * wextreme\n",
    "        estimate = max(0, min(1, barwr - gammastarovern * barwr - betastarovern * barwsqr))\n",
    "        missing = 1 - max(0, min(1, barw - gammastarovern * barw - betastarovern * barwsq))\n",
    "        \n",
    "#         estimate = sum(c*w*r*max(0, 1 - factor*(w - wextreme)) for c, w, r in data) / n\n",
    "#         missing = max(0, 1 - sum(c*w*max(0, 1 - factor*(w - wextreme)) for c, w, r in data) / n)\n",
    "\n",
    "        return estimate + 0.5 * missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((array([5.49000000e-01, 4.50901804e-01, 9.81963869e-05]), array([   0,    2, 1000])), (0, 1000), 99.99999410674329)\n",
      "****** Constant 0.5 ******\n",
      "****** ClippedDR ******\n",
      "****** SNIPS ******\n",
      "****** Euclidean ******\n",
      "****** MLE ******\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import environments.ControlledRangeVariance\n",
    "import MLE.MLE\n",
    "\n",
    "reload(environments.ControlledRangeVariance)\n",
    "reload(MLE.MLE)\n",
    "\n",
    "def getenv():\n",
    "    wsupport = [ 0, 2, 1000 ]\n",
    "    env = environments.ControlledRangeVariance.ControlledRangeVariance(seed=45, wsupport=wsupport, expwsq=100)\n",
    "    return env, env.getpw(), env.range(), env.expectedwsq()\n",
    "    \n",
    "print(getenv()[1:])\n",
    "wmax = getenv()[2][1]\n",
    "\n",
    "FlassPlot.forpaper()\n",
    "for (name, method) in [ \n",
    "                        ('Constant 0.5', lambda **kwargs: 0.5),\n",
    "                        ('ClippedDR', ClippedDR.estimate),\n",
    "                        ('SNIPS', SNIPS.estimate),\n",
    "                        ('Euclidean', Euclidean.estimate),\n",
    "                        ('MLE', lambda data, **kwargs: MLE.MLE.estimate(datagen=lambda: data, **kwargs)[0]),\n",
    "                      ]:\n",
    "    print('****** {} ******'.format(name))\n",
    "    res = []\n",
    "    for zzz in produceresults(getenv()[0], method, numpts=14, ndataperpt=10000):\n",
    "        res.append(zzz)\n",
    "        #print('{}'.format(zzz), flush=True)\n",
    "    FlassPlot.pic([ x[0] / wmax for x in res], [ x[1]['mse'] for x in res], label=name)\n",
    "FlassPlot.axeslabel('n / wmax', 'mse')\n",
    "# FlassPlot.title('synthetic epsilon-greedy: estimation error')\n",
    "#FlassPlot.savefig('epsilongreedy.mse.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
