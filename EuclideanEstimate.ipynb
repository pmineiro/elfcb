{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Log-Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Discretely many importance weights and rewards, maximum likelihood of sample $\\{ (w_i, r_i) \\}$ from $h$ is \n",
    "\\begin{alignat}{2}\n",
    "&\\!\\max_{Q \\succeq 0} &\\qquad& \\sum_n \\log(Q_{w_n, r_n}),\\label{eq:mle}\\\\\n",
    "&\\text{subject to} &  & \\vec{w}^\\top Q \\vec{1} = 1, \\tag{$\\beta$} \\label{eq:mle\n",
    "sumw} \\\\\n",
    "&                  &  & \\vec{1}^\\top Q \\vec{1} = 1. \\tag{$\\gamma$} \\label{eq:m\n",
    "lesum}\n",
    "\\end{alignat}\n",
    "Estimate is $\\hat V(\\pi) = \\vec{w}^\\top \\hat{Q} \\vec{r}$. \n",
    "\n",
    "Dual (ignoring constants) is $$\n",
    "\\begin{aligned}\n",
    "\\sup_{\\beta,\\gamma}& -\\beta - \\gamma + \\sum_{n} \\log\\left(w_n \\beta + \\gamma\\right)\\; \\text{ s.t. } \\; \\forall w,r: w \\beta + \\gamma \\geq 0.\n",
    "\\end{aligned}\n",
    "$$ One dual variable can be eliminated by summing the KKT stationarity conditions and leveraging complementary slackness.  Introducing $\\phi \\succeq 0$ as the (matrix of) dual variables associated with $Q \\succeq 0$: $$\n",
    "\\begin{aligned}\n",
    "\\frac{c_{w_i,r_j}}{q_{w_i,r_j}} &= \\phi_{w_i,r_j} + w_i \\beta + \\gamma \\implies n = 0 + \\beta + \\gamma, \\\\\n",
    "\\end{aligned}\n",
    "$$ resulting in the 1-D dual $$\n",
    "\\begin{aligned}\n",
    "\\sup_{\\beta} & \\sum_{n} \\log\\left((w_n - 1) \\beta + n\\right) \\; \\text{ s.t. } \\;\\forall w,r: (w - 1) \\beta + n \\geq 0.\n",
    "\\end{aligned}\n",
    "$$  This can be solved by 1-D bracketed search on the gradient followed by recovery of the primal values.\n",
    "\n",
    "Primary recovery begins with the primal-dual relationship for observed $(w, r)$ pairs: $$\n",
    "\\hat Q_{w,r} = \\sum_n \\frac{\\mathbb{1}_{w=w_n,r=r_n}}{\\beta^* (w_n - 1) + N}.\n",
    "$$  The MLE will sometimes put mass on unobserved importance weights, in which case the distribution over rewards for that importance weight is not determined.  The unobserved mass can be determined by solving the linear feasibility problem $$\n",
    "\\begin{alignat}{2}\n",
    "& &  & w_{\\min} \\hat{q}_{\\min} + w_{\\max} \\hat{q}_{\\max} = 1 - \\sum_n \\frac{w_n}{\\beta^* (w_n - 1) + N}, \\notag \\\\\n",
    "&                  &  & \\hat{q}_{\\min} + \\hat{q}_{\\max} = 1 - \\sum_n \\frac{1}{\\beta^* (w_n - 1) + N}, \\notag \\\\\n",
    "& & & {\\hat{q}_{\\min} \\geq 0, \\hat{q}_{\\max} \\geq 0},\\notag\n",
    "\\end{alignat}\n",
    "$$\n",
    "where $\\hat{q}_{\\min}$ and $\\hat{q}_{\\max}$ are associated with\n",
    "$w_{\\min}$ and $w_{\\max}$ respectively.  For robustness we convert this into a non-negative least squares problem $$\n",
    "\\begin{alignat}{2}\n",
    "&\\!\\min_{q_{\\min} \\geq 0, q_{\\max} \\geq 0} &\\qquad& \\left\\| \\left(\\begin{array}{cc} 1 & 1 \\\\ w_{\\min} & w_{\\max} \\end{array} \\right) \\left(\\begin{array}{c} q_{\\min} \\\\ q_{\\max} \\end{array}\\right) - \\left(\\begin{array}{c} 1 - \\sum_n \\frac{1}{\\beta^* (w_n - 1) + N} \\\\ 1 - \\sum_n \\frac{w_n}{\\beta^* (w_n - 1) + N} \\end{array} \\right) \\right\\|^2. \\notag\n",
    "\\end{alignat}\n",
    "$$\n",
    "When $q_{\\min} + q_{\\max} > 0$, the MLE is actually an interval; the center of this interval is found using $1/2 (r_{\\min} + r_{\\max})$ as the reward for unobserved importance weights.\n",
    "\n",
    "**Using a baseline:** When using a baseline, pass in shifted rewards and then add the correction to the result.  Given reward predictor $\\hat r: \\mathcal{X} \\times A \\to [r_{\\min}, r_{\\max}]$, construct data for the MLE $$\n",
    "\\begin{aligned}\n",
    "(w_n, \\tilde r_n) &\\leftarrow \\left(\\frac{\\pi(a_n|x_n)}{h(a_n|x_n)}, r_n - \\hat\n",
    "r(x_n, a_n) \\right),\n",
    "\\end{aligned}\n",
    "$$ apply the MLE on this data (with modified $\\tilde r_{\\min}$ and $\\tilde r_{\\max}$), and then adjust the result via $$\n",
    "\\begin{aligned}\n",
    "\\hat V^{\\text{(rpmle)}} &= \\hat V^{\\text{(mle)}} + \\sum_n \\sum_a \\pi(a_n|x_n) \\hat r(x_n, a_n).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**With censorship**: Suppose some $r_j = \\varnothing$ implying the reward was exogenously censored, and suppose we want to estimate $$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}\\left[r | r \\neq \\varnothing\\right] = \\frac{\\mathbb{E}\\left[r 1_{r \\neq \\varnothing}\\right]}{\\mathbb{E}\\left[1_{r \\neq \\varnothing}\\right]}.\n",
    "\\end{aligned}\n",
    "$$ One possible estimate is $$\n",
    "\\begin{aligned}\n",
    "\\hat V(\\pi) = \\frac{w^\\top Q (r 1_{r \\neq \\varnothing})}{w^\\top Q 1_{r \\neq \\varnothing}}\n",
    "\\end{aligned}\n",
    "$$ which is straightforward when there is no mass assigned to unobserved importance weights.  When there is mass assigned to unobserved importance weights, the MLE is again an interval and we can choose the center point of the interval as the estimate.\n",
    "\n",
    "In python we represent censored rewards with `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Assume no duplicates and reduplicate at the end.\n",
    "$$\n",
    "\\begin{alignat}{2}\n",
    "&\\!\\min_{Q \\succeq 0} &\\qquad& \\sum_{n} \\frac{1}{2} \\left(N Q_{w_n,r_n} - 1\\right)^2,\\label{eq:mle}\\\\\n",
    "&\\text{subject to} &  & \\vec{w}^\\top Q \\vec{1} = 1, \\tag{$\\beta$} \\label{eq:mlesumw} \\\\\n",
    "&                  &  & \\vec{1}^\\top Q \\vec{1} = 1. \\tag{$\\gamma$} \\label{eq:mlesum}\n",
    "\\end{alignat}\n",
    "$$\n",
    "Lagrangian:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(Q, \\beta, \\gamma) &= \\beta  (\\vec{w}^\\top Q \\vec{1} -1) + \\gamma (\\vec{1} Q \\vec{1} - 1) + \\sum_{n} \\frac{1}{2} \\left(N Q_{w_n,r_n} - 1\\right)^2. \\\\\n",
    "&= -\\beta - \\gamma + \\sum_{w,r} \\left( \\left( \\beta w + \\gamma \\right) Q_{w,r} + \\frac{1}{2} c_{w,r} \\left(N Q_{w,r} - 1\\right)^2 \\right). \\\\\n",
    "\\frac{\\partial}{\\partial Q_{w,r}} L(Q, \\beta, \\gamma) &= \\beta w + \\gamma + c_{w,r} N \\left(N Q_{w,r} - 1\\right) \\\\\n",
    "\\end{aligned}\n",
    "$$ Dual will be unbounded unless $\\forall w: \\beta w + \\gamma \\geq 0$.  $\\beta w + \\gamma = 0$ can only happen everywhere or at $w = w_{\\min}$ or $w = w_{\\max}$ so we will only potentially place undata on an extreme point.  Continuing $\\ldots$\n",
    "<!---\n",
    "1/2 (n q - 1)^2 + (\\[Gamma] + \\[Beta] w) q \n",
    "Solve[D[%, q] == 0, q] // FullSimplify // Collect[#, n]&\n",
    "%% /. %[[1]] // FullSimplify // Collect[#, n]&\n",
    "--->\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Q^*_{w,r} &= \\max\\left\\{0, \\frac{1}{N} - \\frac{\\beta w + \\gamma}{N^2}\\right\\} & (c_{w,r} = 1). \\\\\n",
    "\\end{aligned}\n",
    "$$ The $\\max\\{0,\\ldots\\}$ is difficult to deal with so ignore that for the purpose of finding (approximate) closed-form expressions for the dual variables.  This is equivalent to relaxing the feasible region to measures which are signed on observed values but unsigned on unobserved values.  Continuing $\\ldots$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "g (\\beta, \\gamma) &= \\inf_{Q \\succeq 0} L(Q, \\beta, \\gamma) \\\\\n",
    "&\\geq -\\beta - \\gamma + \\sum_n \\left( \\left( \\beta w_n + \\gamma \\right) \\left(\\frac{1}{N} - \\frac{\\beta w_n + \\gamma}{N^2} \\right) + \\frac{1}{2} \\left(\\frac{\\beta w_n + \\gamma}{N}\\right)^2 \\right) \\\\\n",
    "&= -\\beta - \\gamma + \\sum_n \\left( \\frac{\\beta w_n + \\gamma}{N} - \\frac{(\\beta w_n + \\gamma)^2}{2 N^2} \\right) \\\\\n",
    "&= -\\beta  + \\sum_n \\left( \\frac{\\beta w_n}{N} - \\frac{(\\beta w_n + \\gamma)^2}{2 N^2} \\right) \\\\\n",
    "\\end{aligned}\n",
    "$$ The unconstrained $\\gamma$ optimum is $\\beta \\frac{1}{N} \\sum_n w_n$ but this is infeasible.  Therefore maximizing $\\gamma$ under the constraint is $$\n",
    "\\gamma^* = \\begin{cases} -\\beta w_{\\min} & \\beta > 0 \\\\ -\\beta w_{\\max} & \\beta \\leq 0 \\end{cases} \\doteq -\\beta w_{\\text{sgn}(\\beta)}\n",
    "$$ Substituting we get $$\n",
    "\\begin{aligned}\n",
    "g\\left(\\beta, \\gamma^*(\\beta)\\right) &= -\\beta  + \\sum_n \\left( \\frac{\\beta w_n}{N} - \\frac{\\beta^2 (w_n - w_{\\text{sgn}(\\beta)})^2}{2 N^2} \\right) \\\\\n",
    "&= -\\beta + \\beta \\sum_n \\frac{w_n}{N} - \\beta^2 \\sum_n \\frac{(w_n - w_{\\text{sgn}(\\beta)})^2}{2 N^2} \\\\\n",
    "\\frac{\\partial}{\\partial \\beta} g\\left(\\beta, \\gamma^*(\\beta)\\right) &= -1 + \\sum_n \\frac{w_n}{N} - \\beta \\sum_n \\frac{(w_n - w_{\\text{sgn}(\\beta)})^2}{N^2} \\\\\n",
    "\\beta^* &= \\frac{-1 + \\frac{1}{N} \\sum_n w_n}{\\sum_n \\frac{(w_n - w_{\\text{sgn}(\\beta)})^2}{N^2}} = \\begin{cases}\n",
    "\\frac{-1 + \\frac{1}{N} \\sum_n w_n}{\\sum_n \\frac{(w_n - w_{\\min})^2}{N^2}} & \\frac{1}{N} \\sum_n w_n > 1 \\\\\n",
    "\\frac{-1 + \\frac{1}{N} \\sum_n w_n}{\\sum_n \\frac{(w_n - w_{\\max})^2}{N^2}} & \\frac{1}{N} \\sum_n w_n \\leq 1 \\\\\n",
    "\\end{cases} \\\\\n",
    "g(\\beta^*, \\gamma^*) &= -\\beta^* \\left(-1 + \\frac{1}{N} \\sum_n w_n\\right) + {\\beta^*}^2 \\sum_n \\frac{(w_n - w_{\\text{sgn}(\\beta)})^2}{2 N^2} \\\\ \n",
    "&= \\frac{\\left(-1 + \\frac{1}{N} \\sum_n w_n\\right)^2}{\\sum_n \\frac{(w_n - w_{\\text{sgn}(\\beta)})^2}{N^2}} - \\frac{1}{2} \\frac{\\left(-1 + \\frac{1}{N} \\sum_n w_n\\right)^2}{\\sum_n \\frac{(w_n - w_{\\text{sgn}(\\beta)})^2}{N^2}} \\\\\n",
    "&= \\frac{1}{2} \\frac{\\left(-1 + \\frac{1}{N} \\sum_n w_n\\right)^2}{\\sum_n \\frac{(w_n - w_{\\text{sgn}(\\beta)})^2}{N^2}}\n",
    "\\end{aligned}\n",
    "$$ \n",
    "So (approximately)\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Q^*_{w,r} &=\n",
    "\\begin{cases}\n",
    "\\max\\left\\{0, \\frac{1}{N} - \\frac{1}{N} \\left(\\frac{-1 + \\frac{1}{N} \\sum_n w_n}{\\sum_n \\frac{(w_n - w_{\\min})^2}{N}}\\right)\\left(w - w_{\\min}\\right)\\right\\} & \\frac{1}{N} \\sum_n w_n > 1 \\\\\n",
    "\\max\\left\\{0, \\frac{1}{N} - \\frac{1}{N} \\left(\\frac{-1 + \\frac{1}{N} \\sum_n w_n}{\\sum_n \\frac{(w_n - w_{\\max})^2}{N}}\\right)\\left(w - w_{\\max}\\right)\\right\\} & \\frac{1}{N} \\sum_n w_n \\leq 1 \\\\\n",
    "\\end{cases}\n",
    "& (c_{w,r} > 0).\n",
    "\\end{aligned}\n",
    "$$ and the value estimate is $$\n",
    "\\begin{aligned}\n",
    "\\hat V(\\pi) &= \n",
    "\\begin{cases}\n",
    "\\frac{1}{N} \\sum_n w_n r_n \\max\\left\\{0, 1 - \\left(\\frac{-1 + \\frac{1}{N} \\sum_n w_n}{\\frac{1}{N} \\sum_n (w_n - w_{\\min})^2}\\right)\\left(w_n - w_{\\min}\\right)\\right\\} & \\frac{1}{N} \\sum_n w_n > 1 \\\\\n",
    "\\frac{1}{N} \\sum_n w_n r_n \\max\\left\\{0, 1 - \\left(\\frac{-1 + \\frac{1}{N} \\sum_n w_n}{\\frac{1}{N} \\sum_n (w_n - w_{\\max})^2}\\right)\\left(w_n - w_{\\max}\\right)\\right\\} & \\frac{1}{N} \\sum_n w_n \\leq 1 \\\\\n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "$$ Note both denominators can be computed given $\\frac{1}{N} \\sum_n w_n$ and $\\frac{1}{N} \\sum_n w_n^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cressie-Read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume no duplicates and re-duplicate at the end. $$\n",
    "\\begin{alignat}{2}\n",
    "&\\!\\min_{Q \\succeq 0} &\\qquad& \\frac{2}{\\lambda (1 + \\lambda)} \\sum_n \\left( \\left( N Q_{w_n, r_n} \\right)^{-\\lambda} - 1 \\right),\\label{eq:mle}\\\\\n",
    "&\\text{subject to} &  & \\vec{w}^\\top Q \\vec{1} = 1, \\tag{$\\beta$} \\label{eq:mlesumw} \\\\\n",
    "&                  &  & \\vec{1}^\\top Q \\vec{1} = 1. \\tag{$\\gamma$} \\label{eq:mlesum}\n",
    "\\end{alignat}\n",
    "$$  Dual is $$\n",
    "\\begin{aligned}\n",
    "L (\\beta, \\gamma, Q) &= \\beta \\left(\\vec{w}^\\top Q \\vec{1} - 1\\right) + \\gamma \\left( \\vec{1}^\\top Q \\vec{1} - 1 \\right) + \\frac{2}{\\lambda (1 + \\lambda)} \\sum_n \\left( \\left( N Q_{w_n, r_n} \\right)^{-\\lambda} - 1 \\right) \\\\\n",
    "&= -\\beta - \\gamma + \\sum_{w,r} \\left( \\left( \\gamma + \\beta w \\right) Q_{w,r} + c_{w,r} \\frac{2}{\\lambda (1 + \\lambda)} \\left( \\left( N Q_{w, r} \\right)^{-\\lambda} - 1 \\right) \\right) & \\left( c_{w,r} \\in \\{ 0, 1 \\} \\right).\n",
    "\\end{aligned} \n",
    "$$ This is unbounded unless $\\forall w: \\gamma + \\beta w \\geq 0$. \n",
    "<!--- \n",
    "(\\[Gamma] + \\[Beta] w) Q + (2/(\\[Lambda] (\\[Lambda] + 1)))((N Q)^(-\\[Lambda]) - 1)\n",
    "D[%, Q] == 0\n",
    "Solve[%, Q]\n",
    "%% /. %[[1]] // Simplify // PowerExpand // Simplify\n",
    "(%%%% /. %%[[1]] // Simplify // PowerExpand // FullSimplify // Apart) /. -1 + 1/(1 + \\[Lambda]) -> -\\[Lambda] / (1 + \\[Lambda]) /. 1 - 1 / (1 + \\[Lambda]) -> \\[Lambda] / (1 + \\[Lambda])\n",
    "--->\n",
    "Continuing $\\ldots$ $$\n",
    "\\begin{aligned}\n",
    "0 &= \\gamma + \\beta w - \\frac{2 N}{1 + \\lambda} \\left( N Q_{w, r} \\right)^{-1 - \\lambda} & (c_{w,r} = 1) \\\\\n",
    "\\left( N Q_{w, r} \\right)^{-1 - \\lambda} &= \\frac{1 + \\lambda}{2 N} \\left( \\gamma + \\beta w \\right) \\\\\n",
    "Q_{w,r} &= \\frac{1}{N} \\left( \\frac{1 + \\lambda}{2 N} \\left( \\gamma + \\beta w \\right) \\right)^{\\frac{-1}{1 + \\lambda}}  & \\left( \\lambda > -1 \\right) \\\\\n",
    "\\end{aligned}\n",
    "$$ Substitute $\\gamma \\leftarrow \\gamma \\frac{1 + \\lambda}{2 N}$ and $\\beta \\leftarrow \\beta \\frac{1 + \\lambda}{2 N}$ to get\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Q^*_{w, r} &= \\frac{1}{N} \\left(\\gamma + \\beta w\\right)^{\\frac{-1}{1 + \\lambda}} & \\left( c_{w,r} = 1, \\lambda > -1 \\right) \\\\\n",
    "g (\\beta, \\gamma) &= -\\frac{2 N}{1 + \\lambda} \\beta -\\frac{2 N}{1 + \\lambda} \\gamma - \\frac{2 N}{\\lambda (1 + \\lambda)} + \\sum_n \\left( \\frac{2}{1 + \\lambda} \\left(\\gamma + \\beta w_n\\right) N Q_{w_n, r_n} + \\frac{2}{\\lambda (1 + \\lambda)} N Q_{w_n, r_n} \\left( \\gamma + \\beta w_n \\right) \\right) \\\\\n",
    "&= -\\frac{2 N}{1 + \\lambda} \\beta -\\frac{2 N}{1 + \\lambda} \\gamma - \\frac{2 N}{\\lambda (1 + \\lambda)} + \\frac{2}{\\lambda} \\sum_n \\left(\\gamma + \\beta w_n\\right) N Q_{w_n, r_n} \\\\\n",
    "&= -\\frac{2 N}{1 + \\lambda} \\beta -\\frac{2 N}{1 + \\lambda} \\gamma  - \\frac{2 N}{\\lambda (1 + \\lambda)} + \\frac{2}{\\lambda}  \\sum_n \\left(\\gamma + \\beta w_n\\right)^{\\frac{\\lambda}{1 + \\lambda}} \\\\\n",
    "&= - \\frac{2 N}{\\lambda (1 + \\lambda)} + \\frac{2 N}{(1 + \\lambda)} \\left( -\\beta - \\gamma +  \\frac{1 + \\lambda}{\\lambda N} \\sum_n \\left(\\gamma + \\beta w_n\\right)^{\\frac{\\lambda}{1 + \\lambda}} \\right) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "Just hit it with a generic convex solver $\\ldots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Censorship changes results\n",
    "\n",
    "We learned this the hard way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.17414127154917453,\n",
      " {'betastar': -421.93139841688657,\n",
      "  'num': 159912,\n",
      "  'qex': {0: 2.7755671722026296e-17, 380: 0.0005377660516997341},\n",
      "  'qfunc': <function estimate.<locals>.<lambda> at 0x7f5f3c1f9e18>,\n",
      "  'vmax': 0.276316821372124,\n",
      "  'vmin': 0.07196572172622505})\n",
      "(0.15222508738880963,\n",
      " {'betastar': -708.0158311345647,\n",
      "  'num': 268338,\n",
      "  'qex': {0: 0.0, 380: 0.00022164515295090473},\n",
      "  'qfunc': <function estimate.<locals>.<lambda> at 0x7f5f3c203048>,\n",
      "  'vmax': 0.22764427578168045,\n",
      "  'vmin': 0.07680589899593883})\n"
     ]
    }
   ],
   "source": [
    "data, wmin, wmax, censored = None, None, None, None\n",
    "for data, wmin, wmax, censored in [\n",
    "    # some data where exogenous censorship is discarded\n",
    "   ([ (c, w, r) for c, w, r in [ \n",
    "      (86, -59.999996, 0.0), (44884, -1.0497237, 0.0), (16331, -1.0447762, 0.0), (31257, -1.0344828, 0.0), \n",
    "      (15868, -1.0, 0.0), (41332, 0.0, 0.0), (1958, 0.0, 1.0), (17763, 1.0, 0.0), (1339, 1.0, 1.0), \n",
    "      (30726, 1.0344828, 0.0), (3867, 1.0344828, 1.0), (2034, 1.0447762, 1.0), (16728, 1.0447762, 0.0), \n",
    "      (40629, 1.0497237, 0.0), (3445, 1.0497237, 1.0), (85, 59.999996, 0.0), (6, 59.999996, 1.0), \n",
    "     ]\n",
    "     if w >= 0\n",
    "    ], 0, 380, False),\n",
    "    # same data where exogenous censorship is modeled\n",
    "   ([ (c, -w if w < 0 else w, None if w < 0 else r) for c, w, r in [ \n",
    "      (86, -59.999996, 0.0), (44884, -1.0497237, 0.0), (16331, -1.0447762, 0.0), (31257, -1.0344828, 0.0), \n",
    "      (15868, -1.0, 0.0), (41332, 0.0, 0.0), (1958, 0.0, 1.0), (17763, 1.0, 0.0), (1339, 1.0, 1.0), \n",
    "      (30726, 1.0344828, 0.0), (3867, 1.0344828, 1.0), (2034, 1.0447762, 1.0), (16728, 1.0447762, 0.0), \n",
    "      (40629, 1.0497237, 0.0), (3445, 1.0497237, 1.0), (85, 59.999996, 0.0), (6, 59.999996, 1.0), \n",
    "     ]], 0, 380, True),\n",
    "]:\n",
    "    import MLE.MLE\n",
    "\n",
    "    from pprint import pformat\n",
    "    print(pformat(MLE.MLE.estimate(datagen=lambda: data, \n",
    "                                   wmin=wmin, wmax=wmax, rmin=0, rmax=1, raiseonerr=True, censored=censored)))\n",
    "  \n",
    "del data, wmin, wmax, censored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Comparison with CVX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     4
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# CVXPY (primal) implementation\n",
    "\n",
    "class MLETest:\n",
    "    @staticmethod\n",
    "    def cvxestimate(data, wmin, wmax, rmin, rmax):\n",
    "        import cvxpy as cp\n",
    "        import numpy as np\n",
    "        from collections import defaultdict\n",
    "        \n",
    "        cdict = defaultdict(int)\n",
    "        n = 0\n",
    "        for (ci, wi, ri) in data:\n",
    "            assert ci >= 0\n",
    "            assert wi >= wmin and wi <= wmax\n",
    "            assert ri >= rmin and ri <= rmax\n",
    "            if ci > 0:\n",
    "                cdict[(wi, ri)] += ci\n",
    "            n += ci\n",
    "        assert n >= 1\n",
    "        cdict[(wmin, rmin)] += 0\n",
    "        cdict[(wmin, rmax)] += 0\n",
    "        cdict[(wmax, rmin)] += 0\n",
    "        cdict[(wmax, rmax)] += 0\n",
    "        cdict.default_factory = None\n",
    "        \n",
    "        wvec = np.array(list(set(w for (w, _), _ in cdict.items())))\n",
    "        wmaxvec = np.max(wvec)\n",
    "        rvec = np.array(list(set(r for (_, r), _ in cdict.items())))\n",
    "        C = np.array([ [ cdict.get((w, r), 0)/n for r in rvec ] for w in wvec ])\n",
    "        Q = cp.Variable((len(wvec), len(rvec)))\n",
    "            \n",
    "        prob = cp.Problem(cp.Maximize(cp.sum(cp.multiply(C, cp.log(Q)))), [\n",
    "                                cp.sum(cp.matmul((wvec/wmaxvec).T, Q)) == 1/wmaxvec,\n",
    "                                cp.sum(Q) == 1\n",
    "                          ])\n",
    "        prob.solve(solver='ECOS')\n",
    "            \n",
    "        vhat = 0\n",
    "        for i, wi in enumerate(wvec):\n",
    "            for j, rj in enumerate(rvec):\n",
    "                if cdict.get((wi, rj), 0) > 0:\n",
    "                    vhat += wi * Q.value[i, j] * rj\n",
    "                else:\n",
    "                    vhat += wi * Q.value[i, j] * 0.5 * (rmax - rmin)\n",
    " \n",
    "        from scipy.special import xlogy\n",
    "    \n",
    "        return vhat, { \n",
    "            'qstar': { (wvec[i], rvec[j]): Q.value[i, j] for i in range(len(wvec)) for j in range(len(rvec)) },\n",
    "            'likelihood': np.sum(xlogy(C, Q.value)),\n",
    "            'sumofone': np.sum(Q.value),\n",
    "            'sumofw': np.sum(wvec.dot(Q.value)),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:47<00:00,  7.77s/it]\n"
     ]
    }
   ],
   "source": [
    "def testestimate():\n",
    "    from importlib import reload\n",
    "    from math import ceil\n",
    "    import environments.ControlledRangeVariance\n",
    "    import MLE.MLE\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm as tqdm\n",
    "    import sys\n",
    "\n",
    "    reload(environments.ControlledRangeVariance)\n",
    "    reload(MLE.MLE)\n",
    "\n",
    "    wsupport = [ 0, 2, 20 ]\n",
    "    wmax = wsupport[-1]\n",
    "    env = environments.ControlledRangeVariance.ControlledRangeVariance(seed=45, wsupport=wsupport, expwsq=5)\n",
    "\n",
    "    for ndata in tqdm(map(ceil, np.logspace(1, 7, 14)), file=sys.stderr, total=14):\n",
    "        for i in range(1001):\n",
    "            (truevalue, data) = env.sample(ndata)\n",
    "            vhat, qstar = MLE.MLE.estimate(datagen = lambda: data, wmin=0, wmax=wmax, rmin=0, rmax=1, raiseonerr=True)\n",
    "            cvxvhat, cvxqstar = MLETest.cvxestimate(data, wmin=0, wmax=wmax, rmin=0, rmax=1)\n",
    " \n",
    "            from pprint import pformat\n",
    "            assert np.allclose(vhat, cvxvhat, atol=1e-4), pformat(\n",
    "            {\n",
    "                'data': [(c, w, r) for c, w, r in data if c > 0],\n",
    "                'vhat': vhat,\n",
    "                'cvxvhat': cvxvhat,\n",
    "                'qstar': qstar,\n",
    "                'cvxqstar': cvxqstar,\n",
    "            })\n",
    "                                    \n",
    "testestimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:48<00:00,  7.88s/it]\n"
     ]
    }
   ],
   "source": [
    "def megatestestimate():\n",
    "    from importlib import reload\n",
    "    from math import ceil\n",
    "    import environments.ControlledRangeVariance\n",
    "    import MLE.MLE\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm as tqdm\n",
    "    import sys\n",
    "\n",
    "    reload(environments.ControlledRangeVariance)\n",
    "    reload(MLE.MLE)\n",
    "    \n",
    "    def getenv():\n",
    "        import numpy\n",
    "        wsupport = numpy.geomspace(0.5, 1000, 10)\n",
    "        env = environments.ControlledRangeVariance.ControlledRangeVariance(seed=45, wsupport=wsupport, expwsq=100)\n",
    "        return env, env.getpw(), env.range(), env.expectedwsq()\n",
    "\n",
    "    env = getenv()[0]\n",
    "    wmin, wmax = env.range()\n",
    "    \n",
    "    for ndata in tqdm(map(ceil, np.logspace(1, 7, 14)), file=sys.stderr, total=14):\n",
    "        for i in range(1001):\n",
    "            (truevalue, data) = env.sample(ndata)\n",
    "            vhat, qstar = MLE.MLE.estimate(lambda: data, wmin=wmin, wmax=wmax, rmin=0, rmax=1, raiseonerr=True)\n",
    "            try:\n",
    "                cvxvhat, cvxqstar = MLETest.cvxestimate(data, wmin=wmin, wmax=wmax, rmin=0, rmax=1)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            from pprint import pformat\n",
    "            assert np.allclose(vhat, cvxvhat, atol=1e-4) or not np.isfinite(cvxqstar['likelihood']), pformat(\n",
    "            {\n",
    "                'data': [(c, w, r) for c, w, r in data if c > 0],\n",
    "                'vhat': vhat,\n",
    "                'cvxvhat': cvxvhat,\n",
    "                'qstar': qstar,\n",
    "                'cvxqstar': cvxqstar,\n",
    "            })\n",
    "                                    \n",
    "megatestestimate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "code_folding": [
     0,
     43,
     50,
     58,
     129,
     156
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Euclidean ******\n",
      "****** TwoThirds ******\n",
      "****** MinusOneHalf ******\n",
      "****** One ******\n",
      "****** Almost MLE ******\n",
      "****** MLE ******\n"
     ]
    }
   ],
   "source": [
    "def produceresults(env, method, maxexp=5, numpts=20, ndataperpt=10000):\n",
    "    from math import ceil\n",
    "    import numpy as np\n",
    "    \n",
    "    wmin, wmax = env.range()\n",
    "\n",
    "    for ndata in map(ceil, np.logspace(1, maxexp, numpts)):\n",
    "        estimates=[]\n",
    "        for i in range(1, ndataperpt+1):\n",
    "            (truevalue, data) = env.sample(ndata)\n",
    "            try:\n",
    "                estimate = None\n",
    "                estimate = method(data=data, wmin=wmin, wmax=wmax)\n",
    "                assert np.isfinite(estimate)\n",
    "            except:\n",
    "                print('truevalue was {}'.format(truevalue))\n",
    "                print('data was {}'.format(data))\n",
    "                print('estimate was {}'.format(estimate))\n",
    "                raise\n",
    "            \n",
    "            essden = sum(c*w*w for (c, w, _) in data)\n",
    "            essnum = sum(c*w for (c, w, _) in data)\n",
    "            ess = 0 if essden == 0 else essnum*(essnum/essden)\n",
    "                                                \n",
    "            estimates.append(\n",
    "                ( truevalue,\n",
    "                  truevalue - estimate,\n",
    "                  (truevalue - estimate)**2,\n",
    "                 ess\n",
    "                )  \n",
    "            )\n",
    "            \n",
    "        yield (ndata,\n",
    "                { \n",
    "                    'bias': np.abs(np.mean([ x[1] for x in estimates])),\n",
    "                    'biasstd': np.std([ x[1] for x in estimates ], ddof=1) / np.sqrt(len(estimates) - 1),\n",
    "                    'mse': np.mean([ x[2] for x in estimates ]),\n",
    "                    'msestd': np.std( [ x[2] for x in estimates ], ddof=1) / np.sqrt(len(estimates) - 1),\n",
    "                    'ess': np.mean([ x[3] for x in estimates ]),\n",
    "                    'essstd': np.std([ x[3] for x in estimates ], ddof=1) / np.sqrt(len(estimates) - 1),\n",
    "                },\n",
    "              )\n",
    " \n",
    "class ClippedDR:\n",
    "    @staticmethod\n",
    "    def estimate(data, baseline=0.5, **kwargs):\n",
    "        import numpy as np\n",
    "        n = sum(c for c, _, _ in data)\n",
    "        return baseline if n == 0 else np.clip(sum(c*w*(r-baseline)+c*baseline for c, w, r in data) / n, a_min=0, a_max=1)\n",
    "    \n",
    "class SNIPS:\n",
    "    @staticmethod\n",
    "    def estimate(data, **kwargs):\n",
    "        effn = sum(c*w for c, w, _ in data)\n",
    "        return 0.5 if effn == 0 else sum(c*w*r for c, w, r in data) / effn\n",
    "\n",
    "class Euclidean:\n",
    "    @staticmethod\n",
    "    def estimate(data, wmin, wmax, **kwargs):\n",
    "        n = sum(c for c, _, _ in data)\n",
    "        barw = sum(c*w for c, w, _ in data) / n\n",
    "        barwsq = sum(c*w*w for c, w, _ in data) / n\n",
    "        barwr = sum(c*w*r for c, w, r in data) / n\n",
    "        barwsqr = sum(c*w*w*r for c, w, r in data) / n\n",
    "        barwsq = sum(c*w*w for c, w, r in data) / n\n",
    "        \n",
    "        data = None # sufficient statistics only (!)\n",
    "\n",
    "        wextreme = wmin if barw > 1 else wmax\n",
    "        denom = barwsq - 2 * wextreme * barw + wextreme * wextreme\n",
    "        factor = (barw - 1) / denom\n",
    "\n",
    "        betastarovern = (barw - 1) / denom\n",
    "        gammastarovern = -betastarovern * wextreme\n",
    "        estimate = max(0, min(1, barwr - gammastarovern * barwr - betastarovern * barwsqr))\n",
    "        missing = 1 - max(0, min(1, barw - gammastarovern * barw - betastarovern * barwsq))\n",
    "        \n",
    "#         estimate = sum(c*w*r*max(0, 1 - factor*(w - wextreme)) for c, w, r in data) / n\n",
    "#         missing = max(0, 1 - sum(c*w*max(0, 1 - factor*(w - wextreme)) for c, w, r in data) / n)\n",
    "\n",
    "        return estimate + 0.5 * missing\n",
    "\n",
    "class CressieRead:\n",
    "    @staticmethod\n",
    "    def dualobjective(gamma, beta, data, n, lam):\n",
    "        lampow = lam / (1 + lam)\n",
    "        dual = - gamma - beta\n",
    "        dual += (1 / lampow) * sum((c/n) * (gamma + beta * w)**lampow for c, w, _ in data)\n",
    "        return -dual\n",
    "    \n",
    "    @staticmethod\n",
    "    def jacdualobjective(gamma, beta, data, n, lam):       \n",
    "        lampow = lam / (1 + lam)\n",
    "        j = [ -1, -1 ]\n",
    "        for c, w, _ in data:\n",
    "            dx = (c/n) * (gamma + beta * w)**(lampow - 1)\n",
    "            j[0] += dx\n",
    "            j[1] += dx * w\n",
    "            \n",
    "        return -j[0], -j[1]\n",
    "        \n",
    "    @staticmethod\n",
    "    def hessdualobjective(gamma, beta, data, n, lam):\n",
    "        lampow = lam / (1 + lam)\n",
    "        h = [ 0, 0, 0 ]\n",
    "        for c, w, _ in data:\n",
    "#             dx = (c/n) * (gamma + beta * w)**(lampow - 1)\n",
    "            d2x = (c/n) * (lampow - 1) * (gamma + beta * w)**(lampow - 2)\n",
    "            h[0] += d2x \n",
    "            h[1] += d2x * w\n",
    "            h[2] += d2x * w * w\n",
    "            \n",
    "        return [ [ -h[0], -h[1] ], [ -h[1], -h[2] ] ]\n",
    "    \n",
    "    @staticmethod\n",
    "    def estimate(data, wmin, wmax, lam, **kwargs):\n",
    "        from cvxopt import matrix, solvers\n",
    "        \n",
    "        rmin = kwargs.pop('rmin', 0)\n",
    "        rmax = kwargs.pop('rmax', 1)\n",
    "        \n",
    "        n = sum(c for c, _, _ in data)\n",
    "        assert n > 0\n",
    "        \n",
    "        x0 = 1.0, 0.0\n",
    "        \n",
    "        G = matrix([ [ -1.0, -float(w)  ] for w in (wmin, wmax) ])\n",
    "        h = matrix([ 0.0 for w in (wmin, wmax) ])\n",
    "\n",
    "        if False:\n",
    "#             import MLE.MLE\n",
    "#             from numpy import array as arr\n",
    "#             MLE.MLE.gradcheck(f = lambda x: CressieRead.dualobjective(x[0], x[1], data, n, lam),\n",
    "#                               jac = lambda x: arr(CressieRead.jacdualobjective(x[0], x[1], data, n, lam)),\n",
    "#                               x = x0,\n",
    "#                               what='dualobjective',\n",
    "#                               eps = 1e-6)\n",
    "#             MLE.MLE.hesscheck(jac = lambda x: arr(CressieRead.jacdualobjective(x[0], x[1], data, n, lam)),\n",
    "#                               hess = lambda x: arr(CressieRead.hessdualobjective(x[0], x[1], data, n, lam)),\n",
    "#                               x = x0,\n",
    "#                               what='jacdualobjective')\n",
    "            pass\n",
    "        \n",
    "        def F(x=None, z=None):\n",
    "            if x is None: return 0, matrix(x0)\n",
    "            if any(x[0] + x[1] * w <= 0 for _, w, _ in data):\n",
    "                return None\n",
    "            f = CressieRead.dualobjective(x[0], x[1], data, n, lam)\n",
    "            jf = CressieRead.jacdualobjective(x[0], x[1], data, n, lam)\n",
    "            Df = matrix(jf).T\n",
    "            if z is None: return f, Df\n",
    "            hf = CressieRead.hessdualobjective(x[0], x[1], data, n, lam)\n",
    "            H = z[0] * matrix(hf)\n",
    "            return f, Df, H\n",
    "        \n",
    "        soln = solvers.cp(F, G, h, options={'show_progress': False })\n",
    "        if False:\n",
    "            if soln['status'] != 'optimal':\n",
    "                import sys\n",
    "                print('.', file=sys.stderr, end='')\n",
    "\n",
    "        fstar = -(2 * n / (lam * (1 + lam))) * (1 + lam * soln['primal objective'])\n",
    "        (gammastar, betastar) = soln['x']\n",
    "                \n",
    "        estimate = sum((c/n) * w * r * (gammastar + betastar * w)**(-1 / (1 + lam)) for c, w, r in data)\n",
    "        missing = max(0, 1 - sum((c/n) * w * 1 * (gammastar + betastar * w)**(-1 / (1 + lam)) for c, w, _ in data))\n",
    "        \n",
    "        return max(0, min(1, estimate + 0.5 * missing))\n",
    "     \n",
    "from importlib import reload\n",
    "import environments.ControlledRangeVariance\n",
    "import MLE.MLE\n",
    "\n",
    "reload(environments.ControlledRangeVariance)\n",
    "reload(MLE.MLE)\n",
    "\n",
    "def getenv():\n",
    "    wsupport = [ 0, 2, 1000 ]\n",
    "    env = environments.ControlledRangeVariance.ControlledRangeVariance(seed=45, wsupport=wsupport, expwsq=100)\n",
    "    return env, env.getpw(), env.range(), env.expectedwsq()\n",
    "\n",
    "allres = []\n",
    "for (name, method) in [ \n",
    "#                         ('Constant 0.5', lambda **kwargs: 0.5),\n",
    "#                         ('ClippedDR', ClippedDR.estimate),\n",
    "#                         ('SNIPS', SNIPS.estimate),\n",
    "                        ('Euclidean', Euclidean.estimate),\n",
    "                        ('TwoThirds', lambda *args, **kwargs: CressieRead.estimate(*args, **kwargs, lam=2/3)),\n",
    "                        ('MinusOneHalf', lambda *args, **kwargs: CressieRead.estimate(*args, **kwargs, lam=-1/2)),\n",
    "                        ('One', lambda *args, **kwargs: CressieRead.estimate(*args, **kwargs, lam=1)),\n",
    "                        ('Almost MLE', lambda *args, **kwargs: CressieRead.estimate(*args, **kwargs, lam=1e-2)),\n",
    "                        ('MLE', lambda data, **kwargs: MLE.MLE.estimate(datagen=lambda: data, **kwargs)[0]),\n",
    "                      ]:\n",
    "    print('****** {} ******'.format(name))\n",
    "    res = []\n",
    "    for zzz in produceresults(getenv()[0], method, numpts=14, ndataperpt=10000):\n",
    "        res.append(zzz)\n",
    "#         print('{}'.format(zzz), flush=True)\n",
    "    wmax = getenv()[2][1]\n",
    "    allres.append((name, [(x[0] / wmax, x[1]) for x in res]))\n",
    "    del wmax\n",
    "import pickle\n",
    "pickle.dump( allres, open( \"epsilongreedy_estimate_euclideanres.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "class FlassPlot:\n",
    "    @staticmethod\n",
    "    def pic(x, y, label):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.loglog(x, y, label=label)\n",
    "        plt.legend()\n",
    "        \n",
    "    @staticmethod\n",
    "    def forpaper():\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        LEGEND_SIZE = 12\n",
    "        SMALL_SIZE = 16\n",
    "        MEDIUM_SIZE = 22\n",
    "        BIGGER_SIZE = 24\n",
    "\n",
    "        plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "        plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "        plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "        plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "        plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "        plt.rc('legend', fontsize=LEGEND_SIZE)    # legend fontsize\n",
    "        plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "        \n",
    "    @staticmethod\n",
    "    def axeslabel(xlabel, ylabel):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        \n",
    "    @staticmethod\n",
    "    def title(title):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.title(title)\n",
    "        \n",
    "    @staticmethod\n",
    "    def savefig(filename):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "        \n",
    "    @staticmethod\n",
    "    def plt():\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        return plt\n",
    "  \n",
    "import pickle\n",
    "allres = pickle.load(open( \"epsilongreedy_estimate_euclideanres.p\", \"rb\" ) )\n",
    "\n",
    "renameit = { }\n",
    "skip = { 'TwoThirds': 1, 'MinusOneHalf': 1, 'One': 1 }\n",
    "FlassPlot.forpaper()\n",
    "for name, res in allres:\n",
    "    if name in skip:\n",
    "        continue\n",
    "    x = [ x[0] for x in res ]\n",
    "    y = [ x[1]['mse'] for x in res ]\n",
    "    ylo = [ x[1]['mse'] - 1.96 * x[1]['msestd'] for x in res ]\n",
    "    yhi = [ x[1]['mse'] + 1.96 * x[1]['msestd'] for x in res ]\n",
    "    FlassPlot.plt().loglog([ x[0] for x in res ], [ x[1]['mse'] for x in res ], label=renameit.get(name, name))\n",
    "    FlassPlot.plt().fill_between(x, ylo, yhi, alpha=0.7)\n",
    "FlassPlot.plt().legend()\n",
    "\n",
    "FlassPlot.axeslabel('n / $w_{max}$', 'mse')\n",
    "#FlassPlot.plt().savefig(\"epsilongreedy_mse.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
