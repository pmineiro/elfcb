{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## K-L divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Discretely many importance weights and rewards, maximum likelihood of sample $\\{ (w_i, r_i) \\}$ from $h$ is \n",
    "\\begin{alignat}{2}\n",
    "&\\!\\max_{Q \\succeq 0} &\\qquad& \\sum_n \\log(Q_{w_n, r_n}),\\label{eq:mle}\\\\\n",
    "&\\text{subject to} &  & \\vec{w}^\\top Q \\vec{1} = 1, \\tag{$\\beta$} \\label{eq:mle\n",
    "sumw} \\\\\n",
    "&                  &  & \\vec{1}^\\top Q \\vec{1} = 1. \\tag{$\\gamma$} \\label{eq:m\n",
    "lesum}\n",
    "\\end{alignat}\n",
    "Estimate is $\\hat V(\\pi) = \\vec{w}^\\top \\hat{Q} \\vec{r}$. \n",
    "\n",
    "Dual (ignoring constants) is $$\n",
    "\\begin{aligned}\n",
    "\\sup_{\\beta,\\gamma}& -\\beta - \\gamma + \\sum_{n} \\log\\left(w_n \\beta + \\gamma\\right)\\; \\text{ s.t. } \\; \\forall w,r: w \\beta + \\gamma \\geq 0.\n",
    "\\end{aligned}\n",
    "$$ One dual variable can be eliminated by summing the KKT stationarity conditions and leveraging complementary slackness.  Introducing $\\phi \\succeq 0$ as the (matrix of) dual variables associated with $Q \\succeq 0$: $$\n",
    "\\begin{aligned}\n",
    "\\frac{c_{w_i,r_j}}{q_{w_i,r_j}} &= \\phi{w_i,r_j} + w_i \\beta + \\gamma \\implies n = 0 + \\beta + \\gamma, \\\\\n",
    "\\end{aligned}\n",
    "$$ resulting in the 1-D dual $$\n",
    "\\begin{aligned}\n",
    "\\sup_{\\beta} & \\sum_{n} \\log\\left((w_n - 1) \\beta + n\\right) \\; \\text{ s.t. } \\;\\forall w,r: (w - 1) \\beta + n \\geq 0.\n",
    "\\end{aligned}\n",
    "$$  This can be solved by 1-D bracketed search on the gradient followed by recovery of the primal values.\n",
    "\n",
    "Primary recovery begins with the primal-dual relationship for observed $(w, r)$ pairs: $$\n",
    "\\hat Q_{w,r} = \\sum_n \\frac{\\mathbb{1}_{w=w_n,r=r_n}}{\\beta^* (w_n - 1) + N}.\n",
    "$$  The MLE will sometimes put mass on unobserved importance weights, in which case the distribution over rewards for that importance weight is not determined.  The unobserved mass can be determined by solving the linear feasibility problem $$\n",
    "\\begin{alignat}{2}\n",
    "& &  & w_{\\min} \\hat{q}_{\\min} + w_{\\max} \\hat{q}_{\\max} = 1 - \\sum_n \\frac{w_n}{\\beta^* (w_n - 1) + N}, \\notag \\\\\n",
    "&                  &  & \\hat{q}_{\\min} + \\hat{q}_{\\max} = 1 - \\sum_n \\frac{1}{\\beta^* (w_n - 1) + N}, \\notag \\\\\n",
    "& & & {\\hat{q}_{\\min} \\geq 0, \\hat{q}_{\\max} \\geq 0},\\notag\n",
    "\\end{alignat}\n",
    "$$\n",
    "where $\\hat{q}_{\\min}$ and $\\hat{q}_{\\max}$ are associated with\n",
    "$w_{\\min}$ and $w_{\\max}$ respectively.  For robustness we convert this into a non-negative least squares problem $$\n",
    "\\begin{alignat}{2}\n",
    "&\\!\\min_{q_{\\min} \\geq 0, q_{\\max} \\geq 0} &\\qquad& \\left\\| \\left(\\begin{array}{cc} 1 & 1 \\\\ w_{\\min} & w_{\\max} \\end{array} \\right) \\left(\\begin{array}{c} q_{\\min} \\\\ q_{\\max} \\end{array}\\right) - \\left(\\begin{array}{c} 1 - \\sum_n \\frac{1}{\\beta^* (w_n - 1) + N} \\\\ 1 - \\sum_n \\frac{w_n}{\\beta^* (w_n - 1) + N} \\end{array} \\right) \\right\\|^2. \\notag\n",
    "\\end{alignat}\n",
    "$$\n",
    "When $q_{\\min} + q_{\\max} > 0$, the MLE is actually an interval; the center of this interval is found using $1/2 (r_{\\min} + r_{\\max})$ as the reward for unobserved importance weights.\n",
    "\n",
    "**Using a baseline:** When using a baseline, pass in shifted rewards and then add the correction to the result.  Given reward predictor $\\hat r: \\mathcal{X} \\times A \\to [r_{\\min}, r_{\\max}]$, construct data for the MLE $$\n",
    "\\begin{aligned}\n",
    "(w_n, \\tilde r_n) &\\leftarrow \\left(\\frac{\\pi(a_n|x_n)}{h(a_n|x_n)}, r_n - \\hat\n",
    "r(x_n, a_n) \\right),\n",
    "\\end{aligned}\n",
    "$$ apply the MLE on this data (with modified $\\tilde r_{\\min}$ and $\\tilde r_{\\max}$), and then adjust the result via $$\n",
    "\\begin{aligned}\n",
    "\\hat V^{\\text{(rpmle)}} &= \\hat V^{\\text{(mle)}} + \\sum_n \\sum_a \\pi(a_n|x_n) \\hat r(x_n, a_n).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**With censorship**: Suppose some $r_j = \\varnothing$ implying the reward was exogenously censored, and suppose we want to estimate $$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}\\left[r | r \\neq \\varnothing\\right] = \\frac{\\mathbb{E}\\left[r 1_{r \\neq \\varnothing}\\right]}{\\mathbb{E}\\left[1_{r \\neq \\varnothing}\\right]}.\n",
    "\\end{aligned}\n",
    "$$ One possible estimate is $$\n",
    "\\begin{aligned}\n",
    "\\hat V(\\pi) = \\frac{w^\\top Q (r 1_{r \\neq \\varnothing})}{w^\\top Q 1_{r \\neq \\varnothing}}\n",
    "\\end{aligned}\n",
    "$$ which is straightforward when there is no mass assigned to unobserved importance weights.  When there is mass assigned to unobserved importance weights, the MLE is again an interval and we can choose the center point of the interval as the estimate.\n",
    "\n",
    "In python we represent censored rewards with `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume no duplicates for now (infinitesmal futzing, $c_{w,r} = 0$ or $1$).\n",
    "$$\n",
    "\\begin{alignat}{2}\n",
    "&\\!\\min_{Q \\succeq 0} &\\qquad& \\sum_{n} \\frac{1}{2} \\left(N Q_{w_n,r_n} - 1\\right)^2,\\label{eq:mle}\\\\\n",
    "&\\text{subject to} &  & \\vec{w}^\\top Q \\vec{1} = 1, \\tag{$\\beta$} \\label{eq:mlesumw} \\\\\n",
    "&                  &  & \\vec{1}^\\top Q \\vec{1} = 1. \\tag{$\\gamma$} \\label{eq:mlesum}\n",
    "\\end{alignat}\n",
    "$$\n",
    "Langragian:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(Q, \\beta, \\gamma) &= \\beta  (\\vec{w}^\\top Q \\vec{1} -1) + \\gamma (\\vec{1} Q \\vec{1} - 1) + \\sum_{n} \\frac{1}{2} \\left(N Q_{w_n,r_n} - 1\\right)^2. \\\\\n",
    "&= -\\beta - \\gamma + \\sum_{w,r} \\left( \\left( \\beta w + \\gamma \\right) Q_{w,r} + \\frac{1}{2} c_{w,r} \\left(N Q_{w,r} - 1\\right)^2 \\right). \\\\\n",
    "\\frac{\\partial}{\\partial Q_{w,r}} L(Q, \\beta, \\gamma) &= \\beta w + \\gamma + c_{w,r} N \\left(N Q_{w,r} - 1\\right) \\\\\n",
    "\\end{aligned}\n",
    "$$ Dual will be unbounded unless $\\forall w: \\beta w + \\gamma \\geq 0 \\lor c_{w,r} > 0$.  With infinistemal futzing, this \n",
    "is equivalent to $\\forall w: \\beta w + \\gamma \\geq 0$.  $\\beta w + \\gamma = 0$ can only happen everywhere or at $w = w_{\\min}$ or $w = w_{\\max}$ so we will only potentially place undata on an extreme point.  Continuing $\\ldots$\n",
    "<!---\n",
    "1/2 (n q - 1)^2 + (\\[Gamma] + \\[Beta] w) q \n",
    "Solve[D[%, q] == 0, q] // FullSimplify // Collect[#, n]&\n",
    "%% /. %[[1]] // FullSimplify // Collect[#, n]&\n",
    "--->\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Q^*_{w,r} &= \\max\\left\\{0, \\frac{1}{N} - \\frac{\\beta w + \\gamma}{N^2}\\right\\} & (c_{w,r} = 1). \\\\\n",
    "\\end{aligned}\n",
    "$$ The $\\max\\{0,\\ldots\\}$ is difficult to deal with so ignore that for the purpose of finding (approximate) closed-form expressions for the dual variables.  Continuing $\\ldots$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "g (\\beta, \\gamma) &= \\inf_{Q \\succeq 0} L(Q, \\beta, \\gamma) \\\\\n",
    "&\\geq -\\beta - \\gamma + \\sum_n \\left( \\left( \\beta w_n + \\gamma \\right) \\left(\\frac{1}{N} - \\frac{\\beta w_n + \\gamma}{N^2} \\right) + \\frac{1}{2} \\left(\\frac{\\beta w_n + \\gamma}{N}\\right)^2 \\right) \\\\\n",
    "&= -\\beta - \\gamma + \\sum_n \\left( \\frac{\\beta w_n + \\gamma}{N} - \\frac{(\\beta w_n + \\gamma)^2}{2 N^2} \\right) \\\\\n",
    "&= -\\beta  + \\sum_n \\left( \\frac{\\beta w_n}{N} - \\frac{(\\beta w_n + \\gamma)^2}{2 N^2} \\right) \\\\\n",
    "\\end{aligned}\n",
    "$$ The unconstrained $\\gamma$ optimum is $\\beta \\frac{1}{N} \\sum_n w_n$ but this is infeasible.  Therefore maximizing $\\gamma$ under the constraint is $$\n",
    "\\gamma^* = \\begin{cases} -\\beta w_{\\min} & \\beta > 0 \\\\ -\\beta w_{\\max} & \\beta \\leq 0 \\end{cases} \\doteq -\\beta w_{\\text{sgn}(\\beta)}\n",
    "$$ Substituting we get $$\n",
    "\\begin{aligned}\n",
    "g\\left(\\beta, \\gamma^*(\\beta)\\right) &= -\\beta  + \\sum_n \\left( \\frac{\\beta w_n}{N} - \\frac{\\beta^2 (w_n - w_{\\text{sgn}(\\beta)})^2}{2 N^2} \\right) \\\\\n",
    "&= -\\beta + \\beta \\sum_n \\frac{w_n}{N} - \\beta^2 \\sum_n \\frac{(w_n - w_{\\text{sgn}(\\beta)})^2}{2 N^2} \\\\\n",
    "\\frac{\\partial}{\\partial \\beta} g\\left(\\beta, \\gamma^*(\\beta)\\right) &= -1 + \\sum_n \\frac{w_n}{N} - \\beta \\sum_n \\frac{(w_n - w_{\\text{sgn}(\\beta)})^2}{N^2} \\\\\n",
    "\\beta^* &= \\frac{\\left(\\frac{1}{N} \\sum_n w_n\\right) - 1}{\\sum_n \\frac{(w_n - w_{\\text{sgn}(\\beta)})^2}{N^2}} = \\begin{cases}\n",
    "\\frac{\\left(\\frac{1}{N} \\sum_n w_n\\right) - 1}{\\sum_n \\frac{(w_n - w_{\\min})^2}{N^2}} & \\frac{1}{N} \\sum_n w_n > 1 \\\\\n",
    "\\frac{\\left(\\frac{1}{N} \\sum_n w_n\\right) - 1}{\\sum_n \\frac{(w_n - w_{\\max})^2}{N^2}} & \\frac{1}{N} \\sum_n w_n \\leq 1 \\\\\n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "$$ \n",
    "So (approximately)\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Q^*_{w,r} &=\n",
    "\\begin{cases}\n",
    "\\max\\left\\{0, \\frac{1}{N} - \\frac{1}{N} \\left(\\frac{\\left(\\frac{1}{N} \\sum_n w_n\\right) - 1}{\\sum_n \\frac{(w_n - w_{\\min})^2}{N}}\\right)\\left(w - w_{\\min}\\right)\\right\\} & \\frac{1}{N} \\sum_n w_n > 1 \\\\\n",
    "\\max\\left\\{0, \\frac{1}{N} - \\frac{1}{N} \\left(\\frac{\\left(\\frac{1}{N} \\sum_n w_n\\right) - 1}{\\sum_n \\frac{(w_n - w_{\\max})^2}{N}}\\right)\\left(w - w_{\\max}\\right)\\right\\} & \\frac{1}{N} \\sum_n w_n \\leq 1 \\\\\n",
    "\\end{cases}\n",
    "& (c_{w,r} > 0).\n",
    "\\end{aligned}\n",
    "$$ and the value estimate is $$\n",
    "\\begin{aligned}\n",
    "\\hat V(\\pi) &= \n",
    "\\begin{cases}\n",
    "\\frac{1}{N} \\sum_n w_n r_n \\max\\left\\{0, 1 - \\left(\\frac{\\left(\\frac{1}{N} \\sum_n w_n\\right) - 1}{\\frac{1}{N} \\sum_n (w_n - w_{\\min})^2}\\right)\\left(w_n - w_{\\min}\\right)\\right\\} & \\frac{1}{N} \\sum_n w_n > 1 \\\\\n",
    "\\frac{1}{N} \\sum_n w_n r_n \\max\\left\\{0, 1 - \\left(\\frac{\\left(\\frac{1}{N} \\sum_n w_n\\right) - 1}{\\frac{1}{N} \\sum_n (w_n - w_{\\max})^2}\\right)\\left(w_n - w_{\\max}\\right)\\right\\} & \\frac{1}{N} \\sum_n w_n \\leq 1 \\\\\n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "$$ Note both denominators can be computed given $\\frac{1}{N} \\sum_n w_n$ and $\\frac{1}{N} \\sum_n w_n^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Censorship changes results\n",
    "\n",
    "We learned this the hard way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.17414127154917453,\n",
      " {'betastar': -421.93139841688657,\n",
      "  'num': 159912,\n",
      "  'qex': {0: 2.7755671722026296e-17, 380: 0.0005377660516997341},\n",
      "  'qfunc': <function estimate.<locals>.<lambda> at 0x7f5f3c1f9e18>,\n",
      "  'vmax': 0.276316821372124,\n",
      "  'vmin': 0.07196572172622505})\n",
      "(0.15222508738880963,\n",
      " {'betastar': -708.0158311345647,\n",
      "  'num': 268338,\n",
      "  'qex': {0: 0.0, 380: 0.00022164515295090473},\n",
      "  'qfunc': <function estimate.<locals>.<lambda> at 0x7f5f3c203048>,\n",
      "  'vmax': 0.22764427578168045,\n",
      "  'vmin': 0.07680589899593883})\n"
     ]
    }
   ],
   "source": [
    "data, wmin, wmax, censored = None, None, None, None\n",
    "for data, wmin, wmax, censored in [\n",
    "    # some data where exogenous censorship is discarded\n",
    "   ([ (c, w, r) for c, w, r in [ \n",
    "      (86, -59.999996, 0.0), (44884, -1.0497237, 0.0), (16331, -1.0447762, 0.0), (31257, -1.0344828, 0.0), \n",
    "      (15868, -1.0, 0.0), (41332, 0.0, 0.0), (1958, 0.0, 1.0), (17763, 1.0, 0.0), (1339, 1.0, 1.0), \n",
    "      (30726, 1.0344828, 0.0), (3867, 1.0344828, 1.0), (2034, 1.0447762, 1.0), (16728, 1.0447762, 0.0), \n",
    "      (40629, 1.0497237, 0.0), (3445, 1.0497237, 1.0), (85, 59.999996, 0.0), (6, 59.999996, 1.0), \n",
    "     ]\n",
    "     if w >= 0\n",
    "    ], 0, 380, False),\n",
    "    # same data where exogenous censorship is modeled\n",
    "   ([ (c, -w if w < 0 else w, None if w < 0 else r) for c, w, r in [ \n",
    "      (86, -59.999996, 0.0), (44884, -1.0497237, 0.0), (16331, -1.0447762, 0.0), (31257, -1.0344828, 0.0), \n",
    "      (15868, -1.0, 0.0), (41332, 0.0, 0.0), (1958, 0.0, 1.0), (17763, 1.0, 0.0), (1339, 1.0, 1.0), \n",
    "      (30726, 1.0344828, 0.0), (3867, 1.0344828, 1.0), (2034, 1.0447762, 1.0), (16728, 1.0447762, 0.0), \n",
    "      (40629, 1.0497237, 0.0), (3445, 1.0497237, 1.0), (85, 59.999996, 0.0), (6, 59.999996, 1.0), \n",
    "     ]], 0, 380, True),\n",
    "]:\n",
    "    import MLE.MLE\n",
    "\n",
    "    from pprint import pformat\n",
    "    print(pformat(MLE.MLE.estimate(datagen=lambda: data, \n",
    "                                   wmin=wmin, wmax=wmax, rmin=0, rmax=1, raiseonerr=True, censored=censored)))\n",
    "  \n",
    "del data, wmin, wmax, censored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with CVX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# CVXPY (primal) implementation\n",
    "\n",
    "class MLETest:\n",
    "    @staticmethod\n",
    "    def cvxestimate(data, wmin, wmax, rmin, rmax):\n",
    "        import cvxpy as cp\n",
    "        import numpy as np\n",
    "        from collections import defaultdict\n",
    "        \n",
    "        cdict = defaultdict(int)\n",
    "        n = 0\n",
    "        for (ci, wi, ri) in data:\n",
    "            assert ci >= 0\n",
    "            assert wi >= wmin and wi <= wmax\n",
    "            assert ri >= rmin and ri <= rmax\n",
    "            if ci > 0:\n",
    "                cdict[(wi, ri)] += ci\n",
    "            n += ci\n",
    "        assert n >= 1\n",
    "        cdict[(wmin, rmin)] += 0\n",
    "        cdict[(wmin, rmax)] += 0\n",
    "        cdict[(wmax, rmin)] += 0\n",
    "        cdict[(wmax, rmax)] += 0\n",
    "        cdict.default_factory = None\n",
    "        \n",
    "        wvec = np.array(list(set(w for (w, _), _ in cdict.items())))\n",
    "        wmaxvec = np.max(wvec)\n",
    "        rvec = np.array(list(set(r for (_, r), _ in cdict.items())))\n",
    "        C = np.array([ [ cdict.get((w, r), 0)/n for r in rvec ] for w in wvec ])\n",
    "        Q = cp.Variable((len(wvec), len(rvec)))\n",
    "            \n",
    "        prob = cp.Problem(cp.Maximize(cp.sum(cp.multiply(C, cp.log(Q)))), [\n",
    "                                cp.sum(cp.matmul((wvec/wmaxvec).T, Q)) == 1/wmaxvec,\n",
    "                                cp.sum(Q) == 1\n",
    "                          ])\n",
    "        prob.solve(solver='ECOS')\n",
    "            \n",
    "        vhat = 0\n",
    "        for i, wi in enumerate(wvec):\n",
    "            for j, rj in enumerate(rvec):\n",
    "                if cdict.get((wi, rj), 0) > 0:\n",
    "                    vhat += wi * Q.value[i, j] * rj\n",
    "                else:\n",
    "                    vhat += wi * Q.value[i, j] * 0.5 * (rmax - rmin)\n",
    " \n",
    "        from scipy.special import xlogy\n",
    "    \n",
    "        return vhat, { \n",
    "            'qstar': { (wvec[i], rvec[j]): Q.value[i, j] for i in range(len(wvec)) for j in range(len(rvec)) },\n",
    "            'likelihood': np.sum(xlogy(C, Q.value)),\n",
    "            'sumofone': np.sum(Q.value),\n",
    "            'sumofw': np.sum(wvec.dot(Q.value)),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:47<00:00,  7.77s/it]\n"
     ]
    }
   ],
   "source": [
    "def testestimate():\n",
    "    from importlib import reload\n",
    "    from math import ceil\n",
    "    import environments.ControlledRangeVariance\n",
    "    import MLE.MLE\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm as tqdm\n",
    "    import sys\n",
    "\n",
    "    reload(environments.ControlledRangeVariance)\n",
    "    reload(MLE.MLE)\n",
    "\n",
    "    wsupport = [ 0, 2, 20 ]\n",
    "    wmax = wsupport[-1]\n",
    "    env = environments.ControlledRangeVariance.ControlledRangeVariance(seed=45, wsupport=wsupport, expwsq=5)\n",
    "\n",
    "    for ndata in tqdm(map(ceil, np.logspace(1, 7, 14)), file=sys.stderr, total=14):\n",
    "        for i in range(1001):\n",
    "            (truevalue, data) = env.sample(ndata)\n",
    "            vhat, qstar = MLE.MLE.estimate(datagen = lambda: data, wmin=0, wmax=wmax, rmin=0, rmax=1, raiseonerr=True)\n",
    "            cvxvhat, cvxqstar = MLETest.cvxestimate(data, wmin=0, wmax=wmax, rmin=0, rmax=1)\n",
    " \n",
    "            from pprint import pformat\n",
    "            assert np.allclose(vhat, cvxvhat, atol=1e-4), pformat(\n",
    "            {\n",
    "                'data': [(c, w, r) for c, w, r in data if c > 0],\n",
    "                'vhat': vhat,\n",
    "                'cvxvhat': cvxvhat,\n",
    "                'qstar': qstar,\n",
    "                'cvxqstar': cvxqstar,\n",
    "            })\n",
    "                                    \n",
    "testestimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:48<00:00,  7.88s/it]\n"
     ]
    }
   ],
   "source": [
    "def megatestestimate():\n",
    "    from importlib import reload\n",
    "    from math import ceil\n",
    "    import environments.ControlledRangeVariance\n",
    "    import MLE.MLE\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm as tqdm\n",
    "    import sys\n",
    "\n",
    "    reload(environments.ControlledRangeVariance)\n",
    "    reload(MLE.MLE)\n",
    "    \n",
    "    def getenv():\n",
    "        import numpy\n",
    "        wsupport = numpy.geomspace(0.5, 1000, 10)\n",
    "        env = environments.ControlledRangeVariance.ControlledRangeVariance(seed=45, wsupport=wsupport, expwsq=100)\n",
    "        return env, env.getpw(), env.range(), env.expectedwsq()\n",
    "\n",
    "    env = getenv()[0]\n",
    "    wmin, wmax = env.range()\n",
    "    \n",
    "    for ndata in tqdm(map(ceil, np.logspace(1, 7, 14)), file=sys.stderr, total=14):\n",
    "        for i in range(1001):\n",
    "            (truevalue, data) = env.sample(ndata)\n",
    "            vhat, qstar = MLE.MLE.estimate(lambda: data, wmin=wmin, wmax=wmax, rmin=0, rmax=1, raiseonerr=True)\n",
    "            try:\n",
    "                cvxvhat, cvxqstar = MLETest.cvxestimate(data, wmin=wmin, wmax=wmax, rmin=0, rmax=1)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            from pprint import pformat\n",
    "            assert np.allclose(vhat, cvxvhat, atol=1e-4) or not np.isfinite(cvxqstar['likelihood']), pformat(\n",
    "            {\n",
    "                'data': [(c, w, r) for c, w, r in data if c > 0],\n",
    "                'vhat': vhat,\n",
    "                'cvxvhat': cvxvhat,\n",
    "                'qstar': qstar,\n",
    "                'cvxqstar': cvxqstar,\n",
    "            })\n",
    "                                    \n",
    "megatestestimate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": [
     0,
     42,
     85
    ]
   },
   "outputs": [],
   "source": [
    "def produceresults(env, method, minexp=1, maxexp=5, numpts=20, ndataperpt=10000):\n",
    "    from math import ceil\n",
    "    import numpy as np\n",
    "    \n",
    "    wmin, wmax = env.range()\n",
    "\n",
    "    for ndata in map(ceil, np.logspace(minexp, maxexp, numpts)):\n",
    "        estimates=[]\n",
    "        for i in range(1, ndataperpt+1):\n",
    "            (truevalue, data) = env.sample(ndata)\n",
    "            try:\n",
    "                estimate = None\n",
    "                estimate = method(data=data, wmin=wmin, wmax=wmax)\n",
    "                assert np.isfinite(estimate)\n",
    "            except:\n",
    "                print('truevalue was {}'.format(truevalue))\n",
    "                print('data was {}'.format(data))\n",
    "                print('estimate was {}'.format(estimate))\n",
    "                raise\n",
    "            \n",
    "            essden = sum(c*w*w for (c, w, _) in data)\n",
    "            essnum = sum(c*w for (c, w, _) in data)\n",
    "            ess = 0 if essden == 0 else essnum*(essnum/essden)\n",
    "                                                \n",
    "            estimates.append(\n",
    "                ( truevalue,\n",
    "                  truevalue - estimate,\n",
    "                  (truevalue - estimate)**2,\n",
    "                 ess\n",
    "                )  \n",
    "            )\n",
    "            \n",
    "        yield (ndata,\n",
    "                { \n",
    "                    'bias': np.abs(sum(x[1] for x in estimates) / len(estimates)),\n",
    "                    'mse': sum(x[2] for x in estimates) / len(estimates),\n",
    "                    'ess': sum(x[3] for x in estimates) / len(estimates),\n",
    "                },\n",
    "              )\n",
    "        \n",
    "%matplotlib inline\n",
    "\n",
    "class FlassPlot:\n",
    "    @staticmethod\n",
    "    def pic(x, y, label):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.loglog(x, y, label=label)\n",
    "        plt.legend()\n",
    "        \n",
    "    @staticmethod\n",
    "    def forpaper():\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        SMALL_SIZE = 10\n",
    "        MEDIUM_SIZE = 16\n",
    "        BIGGER_SIZE = 20\n",
    "\n",
    "        plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "        plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "        plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "        plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "        plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "        plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "        plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "        \n",
    "    @staticmethod\n",
    "    def axeslabel(xlabel, ylabel):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        \n",
    "    @staticmethod\n",
    "    def title(title):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.title(title)\n",
    "        \n",
    "    @staticmethod\n",
    "    def savefig(filename):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "    \n",
    "class ClippedDR:\n",
    "    @staticmethod\n",
    "    def estimate(data, baseline=0.5, **kwargs):\n",
    "        import numpy as np\n",
    "        n = sum(c for c, _, _ in data)\n",
    "        return baseline if n == 0 else np.clip(sum(c*w*(r-baseline)+c*baseline for c, w, r in data) / n, a_min=0, a_max=1)\n",
    "    \n",
    "class SNIPS:\n",
    "    @staticmethod\n",
    "    def estimate(data, **kwargs):\n",
    "        effn = sum(c*w for c, w, _ in data)\n",
    "        return 0.5 if effn == 0 else sum(c*w*r for c, w, r in data) / effn\n",
    "    \n",
    "class Euclidean:\n",
    "    @staticmethod\n",
    "    def estimate(data, wmin, wmax, **kwargs):\n",
    "        n = sum(c for c, _, _ in data)\n",
    "        barw = sum(c*w for c, w, _ in data) / n\n",
    "        barwsq = sum(c*w*w for c, w, _ in data) / n\n",
    "        if barw > 1:\n",
    "            wextreme = wmin\n",
    "        else:\n",
    "            wextreme = wmax\n",
    "            \n",
    "        denom = barwsq - 2 * wextreme * barw + wextreme * wextreme\n",
    "        factor = (barw - 1) / denom\n",
    "        estimate = sum(c*w*r*max(0, 1 - factor*(w - wextreme)) for c, w, r in data) / n\n",
    "        missing = max(0, 1 - sum(c*w*max(0, 1 - factor*(w - wextreme)) for c, w, r in data) / n)\n",
    "\n",
    "        return estimate + 0.5 * missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((array([5.49000000e-01, 4.50901804e-01, 9.81963869e-05]), array([   0,    2, 1000])), (0, 1000), 99.99999410674329)\n",
      "****** Constant 0.5 ******\n",
      "****** ClippedDR ******\n",
      "****** SNIPS ******\n",
      "****** Euclidean ******\n",
      "****** MLE ******\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import environments.ControlledRangeVariance\n",
    "import MLE.MLE\n",
    "\n",
    "reload(environments.ControlledRangeVariance)\n",
    "reload(MLE.MLE)\n",
    "\n",
    "def getenv():\n",
    "    wsupport = [ 0, 2, 1000 ]\n",
    "    env = environments.ControlledRangeVariance.ControlledRangeVariance(seed=45, wsupport=wsupport, expwsq=100)\n",
    "    return env, env.getpw(), env.range(), env.expectedwsq()\n",
    "    \n",
    "print(getenv()[1:])\n",
    "wmax = getenv()[2][1]\n",
    "\n",
    "FlassPlot.forpaper()\n",
    "for (name, method) in [ \n",
    "                        ('Constant 0.5', lambda **kwargs: 0.5),\n",
    "                        ('ClippedDR', ClippedDR.estimate),\n",
    "                        ('SNIPS', SNIPS.estimate),\n",
    "                        ('Euclidean', Euclidean.estimate),\n",
    "                        ('MLE', lambda data, **kwargs: MLE.MLE.estimate(datagen=lambda: data, **kwargs)[0]),\n",
    "                      ]:\n",
    "    print('****** {} ******'.format(name))\n",
    "    res = []\n",
    "    for zzz in produceresults(getenv()[0], method, numpts=14, ndataperpt=10000):\n",
    "        res.append(zzz)\n",
    "        #print('{}'.format(zzz), flush=True)\n",
    "    FlassPlot.pic([ x[0] / wmax for x in res], [ x[1]['mse'] for x in res], label=name)\n",
    "FlassPlot.axeslabel('n / wmax', 'mse')\n",
    "# FlassPlot.title('synthetic epsilon-greedy: estimation error')\n",
    "#FlassPlot.savefig('epsilongreedy.mse.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
