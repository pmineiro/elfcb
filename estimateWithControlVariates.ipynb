{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Discretely many importance weights and rewards, control variates $\\vec{\\tau}$, maximum likelihood of sample $\\{ (w_n, r_n, \\vec{\\tau}_n) \\}_{n=1}^N$ from $h$ is \n",
    "\\begin{alignat}{2}\n",
    "&\\!\\max_{Q \\succeq 0} &\\qquad& \\sum_n \\log(Q_{w_n, r_n, \\vec{\\tau}_n}),\\label{eq:mle} \\\\\n",
    "&\\text{subject to} &  & \\sum_{w,r,\\vec{\\tau}} Q_{w,r,\\vec{\\tau}} = 1, \\tag{$\\beta$} \\label{eq:mlesumw} \\\\\n",
    "&                  &  & \\sum_{w,r,\\vec{\\tau}} w Q_{w,r,\\vec{\\tau}} = 1, \\tag{$\\gamma$} \\label{eq:mlesum} \\\\\n",
    "&                  &  & \\sum_{w,r,\\vec{\\tau}} \\vec{\\tau} Q_{w,r,\\vec{\\tau}} = 0, \\tag{$\\vec{\\delta}$} \\label{eq:mlesumdr}\n",
    "\\end{alignat}\n",
    "Estimate is $\\hat V(\\pi) = \\sum_{w,r,\\vec{\\tau}} Q_{w,r,\\vec{\\tau}} w r$.\n",
    "\n",
    "Dual (ignoring constants) is $$\n",
    "\\ldots\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Censorship changes results\n",
    "\n",
    "We learned this the hard way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data, wmin, wmax, censored = None, None, None, None\n",
    "for data, wmin, wmax, censored in [\n",
    "    # some data where exogenous censorship is discarded\n",
    "   ([ (c, w, r) for c, w, r in [ \n",
    "      (86, -59.999996, 0.0), (44884, -1.0497237, 0.0), (16331, -1.0447762, 0.0), (31257, -1.0344828, 0.0), \n",
    "      (15868, -1.0, 0.0), (41332, 0.0, 0.0), (1958, 0.0, 1.0), (17763, 1.0, 0.0), (1339, 1.0, 1.0), \n",
    "      (30726, 1.0344828, 0.0), (3867, 1.0344828, 1.0), (2034, 1.0447762, 1.0), (16728, 1.0447762, 0.0), \n",
    "      (40629, 1.0497237, 0.0), (3445, 1.0497237, 1.0), (85, 59.999996, 0.0), (6, 59.999996, 1.0), \n",
    "     ]\n",
    "     if w >= 0\n",
    "    ], 0, 380, False),\n",
    "    # same data where exogenous censorship is modeled\n",
    "   ([ (c, -w if w < 0 else w, None if w < 0 else r) for c, w, r in [ \n",
    "      (86, -59.999996, 0.0), (44884, -1.0497237, 0.0), (16331, -1.0447762, 0.0), (31257, -1.0344828, 0.0), \n",
    "      (15868, -1.0, 0.0), (41332, 0.0, 0.0), (1958, 0.0, 1.0), (17763, 1.0, 0.0), (1339, 1.0, 1.0), \n",
    "      (30726, 1.0344828, 0.0), (3867, 1.0344828, 1.0), (2034, 1.0447762, 1.0), (16728, 1.0447762, 0.0), \n",
    "      (40629, 1.0497237, 0.0), (3445, 1.0497237, 1.0), (85, 59.999996, 0.0), (6, 59.999996, 1.0), \n",
    "     ]], 0, 380, True),\n",
    "]:\n",
    "    import MLE.MLE\n",
    "\n",
    "    from pprint import pformat\n",
    "    print(pformat(MLE.MLE.estimate(datagen=lambda: data, \n",
    "                                   wmin=wmin, wmax=wmax, rmin=0, rmax=1, raiseonerr=True, censored=censored)))\n",
    "  \n",
    "del data, wmin, wmax, censored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with CVX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0,
     51,
     144
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7845508143539998,\n",
       " [(6, 0, 0, array([ 0, -1])),\n",
       "  (5, 0, 0, array([-1,  0])),\n",
       "  (6, 2, 1, array([1, 0])),\n",
       "  (3, 2, 1, array([0, 1]))],\n",
       " (0.9252209718997872,\n",
       "  {'vmax': 1.0000005451762404,\n",
       "   'vmin': 0.850441398623334,\n",
       "   'qstar': {(0, 0, (0, -1)): 0.29973625073879956,\n",
       "    (0, 0, (-1, 0)): 0.274892585446737,\n",
       "    (2, 1, (1, 0)): 0.27508014492234933,\n",
       "    (2, 1, (0, 1)): 0.15014055438931767},\n",
       "   'qex': {(0, 0, (-1.0, -1.0)): 1.3263744724756783e-07,\n",
       "    (0, 1, (-1.0, -1.0)): 1.3263744724756783e-07,\n",
       "    (1000, 0, (-1.0, -1.0)): 2.3403823948233652e-07,\n",
       "    (1000, 1, (-1.0, -1.0)): 2.3403823948233652e-07,\n",
       "    (0, 0, (-1.0, 999.0)): 3.2553409047166023e-07,\n",
       "    (0, 1, (-1.0, 999.0)): 3.2553409047166023e-07,\n",
       "    (1000, 0, (-1.0, 999.0)): 7.455561498388961e-05,\n",
       "    (1000, 1, (-1.0, 999.0)): 7.455561498388961e-05},\n",
       "   'likelihood': -1.3559347660273615,\n",
       "   'sumofone': 0.9999999940468571,\n",
       "   'sumofw': 1.0000005451762404,\n",
       "   'sumofcvs': array([ 1.05740149e-09, -8.09757323e-10])}),\n",
       " (0.9252040916425025,\n",
       "  {'vmin': 0.850408183285005,\n",
       "   'vmax': 1.0,\n",
       "   'gamma': array(-0.00051131),\n",
       "   'delta': array([ 1.81334428, -0.01769309]),\n",
       "   'qstar': {(0, 0, (0, -1)): 0.299727182417162,\n",
       "    (0, 0, (-1, 0)): 0.274919122470262,\n",
       "    (2, 1, (1, 0)): 0.2750674343009128,\n",
       "    (2, 1, (0, 1)): 0.15013665734158974},\n",
       "   'likelihood': -1.3559374655000074,\n",
       "   'rawsumofone': 0.9998503965299265,\n",
       "   'rawsumofw': 0.850408183285005,\n",
       "   'rawsumofcvs': array([ 1.48311831e-04, -1.49590525e-01])}),\n",
       " (0.9252047490937798,\n",
       "  {'vmin': 0.8504094981875596,\n",
       "   'vmax': 1.0,\n",
       "   'gamma': -2.7701884838481314e-13,\n",
       "   'delta': array([ 1.81278145, -0.01820542]),\n",
       "   'qstar': {(0, 0, (0, -1)): 0.2997271669923924,\n",
       "    (0, 0, (-1, 0)): 0.27491834366192053,\n",
       "    (2, 1, (1, 0)): 0.27506808401167343,\n",
       "    (2, 1, (0, 1)): 0.15013666508210638},\n",
       "   'likelihood': -1.3559374728214408,\n",
       "   'rawsumofw': 0.8504094981875596}))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DoubleDouble:\n",
    "    def __init__(self, numactions, seed, wsupport, expwsq):\n",
    "        import numpy\n",
    "        import environments.ControlledRangeVariance\n",
    "        \n",
    "        self.numactions = numactions\n",
    "        self.state = numpy.random.RandomState(seed+1)\n",
    "        self.env = environments.ControlledRangeVariance.ControlledRangeVariance(seed=seed, wsupport=wsupport, expwsq=expwsq)\n",
    "        \n",
    "    def range(self):\n",
    "        return self.env.range()\n",
    "        \n",
    "    def rawsample(self, ndata):\n",
    "        from collections import Counter\n",
    "        (truevalue, data) = self.env.sample(ndata)\n",
    "        \n",
    "        nicedata = Counter()\n",
    "        for c, w, r in data:\n",
    "            actioncounts = Counter(self.state.choice(a=self.numactions, p=None, size=c))\n",
    "            for pia, ca in actioncounts.items():\n",
    "                nicedata.update({ (w, r, pia): ca })\n",
    "            \n",
    "        return (truevalue, [ (c, w, r, pia) for (w, r, pia), c in nicedata.items() ])\n",
    "            \n",
    "    def sample(self, ndata):\n",
    "        from collections import Counter\n",
    "\n",
    "        (truevalue, data) = self.rawsample(ndata)\n",
    "        nicedata = Counter()\n",
    "        for c, w, r, pia in data:\n",
    "            nicedata.update({ (w, r): c })\n",
    "        return (truevalue, [ (c, w, r) for (w, r), c in nicedata.items() ])\n",
    "    \n",
    "    def samplewithcvs(self, ndata):\n",
    "        from collections import Counter\n",
    "        import numpy\n",
    "\n",
    "        (truevalue, data) = self.rawsample(ndata)\n",
    "   \n",
    "        nicedata = Counter()\n",
    "    \n",
    "        for c, w, r, pia in data:\n",
    "            cvs = tuple(\n",
    "                       w - 1 if a == pia else 0 for a in range(self.numactions)\n",
    "            )\n",
    "            nicedata.update({ (w, r, cvs): c})\n",
    "\n",
    "        return (truevalue, [ (c, w, r, numpy.array(cv)) for (w, r, cv), c in nicedata.items() ])\n",
    "\n",
    "# CVXPY (primal) implementation\n",
    "\n",
    "class MLETest:\n",
    "    @staticmethod\n",
    "    def bitgen(minv, maxv):\n",
    "        def bitgenhelp(vals, minv, maxv, pos, length):\n",
    "            if pos >= length:\n",
    "                yield tuple(vals)\n",
    "            else:\n",
    "                vals[pos] = minv[pos]\n",
    "                yield from bitgenhelp(vals, minv, maxv, pos+1, length)\n",
    "                vals[pos] = maxv[pos]\n",
    "                yield from bitgenhelp(vals, minv, maxv, pos+1, length)\n",
    "            \n",
    "        assert len(minv) == len(maxv)\n",
    "        length = len(minv)\n",
    "        yield from bitgenhelp([None]*length, minv, maxv, 0, length) \n",
    "\n",
    "    @staticmethod\n",
    "    def cvxdualestimate(data, wmin, wmax, cvmin, cvmax, rmin=0, rmax=1):\n",
    "        import cvxpy as cp\n",
    "        import numpy as np\n",
    "        from collections import defaultdict\n",
    "        \n",
    "        cdict = defaultdict(int)\n",
    "        n = 0\n",
    "        for (ci, wi, ri, cvsi) in data:\n",
    "            assert ci >= 0\n",
    "            assert wi >= wmin and wi <= wmax\n",
    "            assert ri >= rmin and ri <= rmax\n",
    "            assert np.all(cvsi >= cvmin)\n",
    "            assert np.all(cvsi <= cvmax)\n",
    "            if ci > 0:\n",
    "                cdict[(wi, ri, tuple(cvsi))] += ci\n",
    "            n += ci\n",
    "            ncvs = len(cvsi)\n",
    "        assert n >= 1\n",
    "        cdict.default_factory = None\n",
    "        \n",
    "        C = np.array([ value / n for key, value in cdict.items() ])\n",
    "        wvec = np.array([ w for (w, _, _), _ in cdict.items() ])\n",
    "        cvsmat = np.array([ cvs for (_, _, cvs), _ in cdict.items() ])\n",
    "\n",
    "        gamma = cp.Variable()\n",
    "        delta = cp.Variable(ncvs)\n",
    "        \n",
    "#         from pprint import pformat\n",
    "#         print(pformat({\n",
    "#             'cdict': cdict,\n",
    "#             'C': C,\n",
    "#             'wvec': wvec,\n",
    "#             'cvsmat': cvsmat,\n",
    "#             'gamma': gamma,\n",
    "#             'delta': delta,\n",
    "#         }))        \n",
    "        \n",
    "        prob = cp.Problem(cp.Maximize(cp.sum(cp.multiply(C, cp.log(n + gamma * (wvec - 1) + cp.matmul(cvsmat, delta))))), [\n",
    "           n + gamma * (w - 1) + cp.matmul(np.array(bitvec), delta) >= 0\n",
    "           for w in (wmin, wmax)\n",
    "           for bitvec in MLETest.bitgen(cvmin, cvmax)\n",
    "        ])\n",
    "        prob.solve(solver='ECOS', max_iters=200)\n",
    "        \n",
    "        Q = np.array([ c / (n + gamma.value * (w - 1) + delta.value.dot(np.array(cvs)))\n",
    "                       for (w, r, cvs), c in cdict.items() ])\n",
    "        rawsumofw = wvec.dot(Q)\n",
    "        rawsumofone = np.sum(Q)\n",
    "        rawsumofcvs = np.matmul(cvsmat.T, Q)\n",
    "        \n",
    "        vhat = 0\n",
    "        for (w, r, cvs), c in cdict.items():\n",
    "            q = c / (n + gamma.value * (w - 1) + delta.value.dot(np.array(cvs)))\n",
    "            vhat += q * w * r\n",
    "           \n",
    "        # NB: no explicit primal reconstruction necessary (!)\n",
    "        vmin = vhat + max(0.0, 1 - rawsumofw) * rmin\n",
    "        vmax = vhat + max(0.0, 1 - rawsumofw) * rmax\n",
    "        vhat += max(0.0, 1 - rawsumofw) * (rmax - rmin) / 2\n",
    "        \n",
    "        from scipy.special import xlogy\n",
    "\n",
    "        return vhat, {\n",
    "            'vmin': vmin,\n",
    "            'vmax': vmax,\n",
    "            'gamma': gamma.value,\n",
    "            'delta': delta.value,\n",
    "            'qstar': { (w, r, cvs): c / (n + gamma.value * (w - 1) + delta.value.dot(np.array(cvs))) \n",
    "                       for (w, r, cvs), c in cdict.items() if c > 0  },\n",
    "            'likelihood': np.sum(xlogy(C, Q)),\n",
    "            'rawsumofone': rawsumofone,\n",
    "            'rawsumofw': rawsumofw,\n",
    "            'rawsumofcvs': rawsumofcvs,\n",
    "        }\n",
    "        \n",
    "    @staticmethod\n",
    "    def cvxestimate(data, wmin, wmax, cvmin, cvmax, rmin=0, rmax=1):\n",
    "        import cvxpy as cp\n",
    "        import numpy as np\n",
    "        from collections import defaultdict\n",
    "        \n",
    "        cdict = defaultdict(int)\n",
    "        n = 0\n",
    "        for (ci, wi, ri, cvsi) in data:\n",
    "            assert ci >= 0\n",
    "            assert wi >= wmin and wi <= wmax\n",
    "            assert ri >= rmin and ri <= rmax\n",
    "            assert np.all(cvsi >= cvmin)\n",
    "            assert np.all(cvsi <= cvmax)\n",
    "            if ci > 0:\n",
    "                cdict[(wi, ri, tuple(cvsi))] += ci\n",
    "            n += ci\n",
    "        assert n >= 1\n",
    "        for bitvec in MLETest.bitgen(cvmin, cvmax):\n",
    "            cdict[(wmin, rmin, bitvec)] += 0\n",
    "            cdict[(wmin, rmax, bitvec)] += 0\n",
    "            cdict[(wmax, rmin, bitvec)] += 0\n",
    "            cdict[(wmax, rmax, bitvec)] += 0\n",
    "        cdict.default_factory = None\n",
    "                       \n",
    "        C = np.array([ value / n for key, value in cdict.items() ])\n",
    "        wvec = np.array([ w for (w, _, _), _ in cdict.items() ])\n",
    "        cvsmat = np.array([ cvs for (_, _, cvs), _ in cdict.items() ])\n",
    "        Q = cp.Variable(len(C))\n",
    "                       \n",
    "#         from pprint import pformat\n",
    "#         print(pformat({\n",
    "#             'cdict': cdict,\n",
    "#             'C': C,\n",
    "#             'wvec': wvec,\n",
    "#             'cvsmat': cvsmat,\n",
    "#             'Q': Q\n",
    "#         }))\n",
    "                       \n",
    "        prob = cp.Problem(cp.Maximize(cp.sum(cp.multiply(C, cp.log(Q)))), [\n",
    "            cp.sum(cp.multiply(wvec / wmax, Q)) == 1 / wmax,\n",
    "            cp.sum(Q) == 1,\n",
    "            cp.matmul(cvsmat.T, Q) == 0\n",
    "        ])\n",
    "        prob.solve(solver='ECOS')\n",
    "        vmax, vmin = 0, 0\n",
    "        for ((w, r, _), c), q in zip(cdict.items(), Q.value):\n",
    "            if c > 0:\n",
    "                vmax += q * w * r\n",
    "                vmin += q * w * r\n",
    "            else:\n",
    "                vmax += q * w * rmax\n",
    "                vmin += q * w * rmin\n",
    "                                          \n",
    "        vhat = (vmin + vmax) / 2              \n",
    " \n",
    "        from scipy.special import xlogy\n",
    "    \n",
    "        return vhat, { \n",
    "            'vmax': vmax,\n",
    "            'vmin': vmin,\n",
    "            'qstar': { key: q for (key, c), q in zip(cdict.items(), Q.value) if c > 0 },\n",
    "            'qex': { key: q for (key, c), q in zip(cdict.items(), Q.value) if c == 0 and q > 0},\n",
    "            'likelihood': np.sum(xlogy(C, Q.value)),\n",
    "            'sumofone': np.sum(Q.value),\n",
    "            'sumofw': wvec.dot(Q.value),\n",
    "            'sumofcvs': np.matmul(cvsmat.T, Q.value)\n",
    "        }\n",
    "    \n",
    "def flass():\n",
    "    from importlib import reload\n",
    "    import numpy as np\n",
    "    import MLE.MLE\n",
    "    reload(MLE.MLE)\n",
    "    \n",
    "    ddm = DoubleDouble(numactions=2, seed=45, wsupport=[0, 2, 1000], expwsq=100)\n",
    "    (truevalue, data) = ddm.samplewithcvs(20)\n",
    "    return (truevalue, data, \n",
    "            MLETest.cvxestimate(data, wmin=0, wmax=1000, cvmin=-1*np.ones(2), cvmax=(1000-1)*np.ones(2)),\n",
    "            MLETest.cvxdualestimate(data, wmin=0, wmax=1000, cvmin=-1*np.ones(2), cvmax=(1000-1)*np.ones(2)),\n",
    "            MLE.MLE.estimatewithcv(lambda: data, wmin=0, wmax=1000, \n",
    "                                   cvmin=-1*np.ones(2), cvmax=(1000-1)*np.ones(2), raiseonerr=True)\n",
    "           ) \n",
    "\n",
    "flass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [05:57<00:00, 87.01s/it]\n"
     ]
    }
   ],
   "source": [
    "def testestimate():\n",
    "    from importlib import reload\n",
    "    from math import ceil\n",
    "    import MLE.MLE\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm as tqdm\n",
    "    import sys\n",
    "\n",
    "    reload(MLE.MLE)\n",
    "\n",
    "    wsupport = [ 0, 2, 10 ]\n",
    "    wmax = wsupport[-1]\n",
    "    env = DoubleDouble(numactions=2, seed=45, wsupport=wsupport, expwsq=5)\n",
    "    \n",
    "    for ndata in tqdm(map(ceil, np.logspace(1, 7, 14)), file=sys.stderr, total=14):\n",
    "        for i in range(101):\n",
    "            (truevalue, data) = env.samplewithcvs(ndata)\n",
    "            vhat, qstar = MLE.MLE.estimatewithcv(lambda: data, wmin=0, wmax=wmax, \n",
    "                                                 cvmin=-1*np.ones(2), cvmax=(wmax-1)*np.ones(2),\n",
    "                                                 raiseonerr=True)\n",
    "            try:\n",
    "                cvxvhat, cvxqstar = MLETest.cvxdualestimate(data, wmin=0, wmax=wmax, \n",
    "                                                            cvmin=-1*np.ones(2), cvmax=(wmax-1)*np.ones(2))\n",
    "            except:\n",
    "                continue\n",
    " \n",
    "            from pprint import pformat\n",
    "            assert (   np.allclose(vhat, cvxvhat, atol=1e-3) \n",
    "                    or np.abs(vhat - truevalue) < np.abs(cvxvhat - truevalue)\n",
    "                    or cvxqstar['rawsumofw'] > 1.001\n",
    "                    or np.allclose(qstar['likelihood'], cvxqstar['likelihood'], atol=1e-4)\n",
    "                   ), pformat(\n",
    "            {\n",
    "                'truevalue': truevalue,\n",
    "                'data': [(c, w, r, cvs) for c, w, r, cvs in data if c > 0],\n",
    "                'vhat': vhat,\n",
    "                'cvxvhat': cvxvhat,\n",
    "                'qstar': qstar,\n",
    "                'cvxqstar': cvxqstar,\n",
    "            })\n",
    "                                    \n",
    "testestimate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     42,
     85,
     92
    ]
   },
   "outputs": [],
   "source": [
    "def produceresults(env, method, maxexp=5, numpts=20, ndataperpt=10000):\n",
    "    from math import ceil\n",
    "    import numpy as np\n",
    "    \n",
    "    wmin, wmax = env.range()\n",
    "\n",
    "    for ndata in map(ceil, np.logspace(1, maxexp, numpts)):\n",
    "        estimates=[]\n",
    "        for i in range(1, ndataperpt+1):\n",
    "            (truevalue, data) = env.sample(ndata)\n",
    "            try:\n",
    "                estimate = None\n",
    "                estimate = method(data=data, wmin=wmin, wmax=wmax)\n",
    "                assert np.isfinite(estimate)\n",
    "            except:\n",
    "                print('truevalue was {}'.format(truevalue))\n",
    "                print('data was {}'.format(data))\n",
    "                print('estimate was {}'.format(estimate))\n",
    "                raise\n",
    "            \n",
    "            essden = sum(c*w*w for (c, w, _) in data)\n",
    "            essnum = sum(c*w for (c, w, _) in data)\n",
    "            ess = 0 if essden == 0 else essnum*(essnum/essden)\n",
    "                                                \n",
    "            estimates.append(\n",
    "                ( truevalue,\n",
    "                  truevalue - estimate,\n",
    "                  (truevalue - estimate)**2,\n",
    "                 ess\n",
    "                )  \n",
    "            )\n",
    "            \n",
    "        yield (ndata,\n",
    "                { \n",
    "                    'bias': np.abs(sum(x[1] for x in estimates) / len(estimates)),\n",
    "                    'mse': sum(x[2] for x in estimates) / len(estimates),\n",
    "                    'ess': sum(x[3] for x in estimates) / len(estimates),\n",
    "                },\n",
    "              )\n",
    "        \n",
    "%matplotlib inline\n",
    "\n",
    "class FlassPlot:\n",
    "    @staticmethod\n",
    "    def pic(x, y, label):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.loglog(x, y, label=label)\n",
    "        plt.legend()\n",
    "        \n",
    "    @staticmethod\n",
    "    def forpaper():\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        SMALL_SIZE = 10\n",
    "        MEDIUM_SIZE = 16\n",
    "        BIGGER_SIZE = 20\n",
    "\n",
    "        plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "        plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "        plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "        plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "        plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "        plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "        plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "        \n",
    "    @staticmethod\n",
    "    def axeslabel(xlabel, ylabel):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        \n",
    "    @staticmethod\n",
    "    def title(title):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.title(title)\n",
    "        \n",
    "    @staticmethod\n",
    "    def savefig(filename):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "    \n",
    "class ClippedDR:\n",
    "    @staticmethod\n",
    "    def estimate(data, baseline=0.5, **kwargs):\n",
    "        import numpy as np\n",
    "        n = sum(c for c, _, _ in data)\n",
    "        return baseline if n == 0 else np.clip(sum(c*w*(r-baseline)+c*baseline for c, w, r in data) / n, a_min=0, a_max=1)\n",
    "    \n",
    "class SNIPS:\n",
    "    @staticmethod\n",
    "    def estimate(data, **kwargs):\n",
    "        effn = sum(c*w for c, w, _ in data)\n",
    "        return 0.5 if effn == 0 else sum(c*w*r for c, w, r in data) / effn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import MLE.MLE\n",
    "\n",
    "reload(MLE.MLE)\n",
    "  \n",
    "class DoubleDouble:\n",
    "    def __init__(self, numactions, seed, wsupport, expwsq):\n",
    "        import numpy\n",
    "        import environments.ControlledRangeVariance\n",
    "        \n",
    "        self.numactions = numactions\n",
    "        self.state = numpy.random.RandomState(seed+1)\n",
    "        self.env = environments.ControlledRangeVariance.ControlledRangeVariance(seed=seed, wsupport=wsupport, expwsq=expwsq)\n",
    "        \n",
    "    def range(self):\n",
    "        return self.env.range()\n",
    "        \n",
    "    def rawsample(self, ndata):\n",
    "        from collections import Counter\n",
    "        (truevalue, data) = self.env.sample(ndata)\n",
    "        \n",
    "        nicedata = Counter()\n",
    "        for c, w, r in data:\n",
    "            actioncounts = Counter(self.state.choice(a=self.numactions, p=None, size=c))\n",
    "            for pia, ca in actioncounts.items():\n",
    "                nicedata.update({ (w, r, pia): ca })\n",
    "            \n",
    "        return (truevalue, [ (c, w, r, pia) for (w, r, pia), c in nicedata.items() ])\n",
    "            \n",
    "    def sample(self, ndata):\n",
    "        from collections import Counter\n",
    "\n",
    "        (truevalue, data) = self.rawsample(ndata)\n",
    "        nicedata = Counter()\n",
    "        for c, w, r, pia in data:\n",
    "            nicedata.update({ (w, r): c })\n",
    "        return (truevalue, [ (c, w, r) for (w, r), c in nicedata.items() ])\n",
    "    \n",
    "    def samplewithcvs(self, ndata):\n",
    "        from collections import Counter\n",
    "        import numpy\n",
    "\n",
    "        (truevalue, data) = self.rawsample(ndata)\n",
    "   \n",
    "        nicedata = Counter()\n",
    "    \n",
    "        for c, w, r, pia in data:\n",
    "            cvs = tuple(\n",
    "                       w - 1 if a == pia else 0 for a in range(self.numactions)\n",
    "            )\n",
    "            nicedata.update({ (w, r, cvs): c})\n",
    "\n",
    "        return (truevalue, [ (c, w, r, numpy.array(cv)) for (w, r, cv), c in nicedata.items() ])\n",
    "\n",
    "def getenv():\n",
    "    ddm = DoubleDouble(numactions=2, seed=5, wsupport=[0, 2, 1000], expwsq=100)\n",
    "    return (ddm, 1000)\n",
    "\n",
    "from pprint import pformat\n",
    "print(pformat(getenv()[0].rawsample(20)))\n",
    "print(pformat(getenv()[0].sample(20)))\n",
    "print(pformat(getenv()[0].samplewithcvs(20)))\n",
    "\n",
    "FlassPlot.forpaper()\n",
    "wmax = getenv()[1]\n",
    "for (name, method) in [ ('Constant 0.5', lambda **kwargs: 0.5),\n",
    "                        ('ClippedDR', ClippedDR.estimate),\n",
    "                        ('SNIPS', SNIPS.estimate),\n",
    "                        ('MLE', lambda data, **kwargs: MLE.MLE.estimate(datagen=lambda: data, **kwargs)[0]),\n",
    "                      ]:\n",
    "    print('****** {} ******'.format(name))\n",
    "    res = []\n",
    "    for zzz in produceresults(getenv()[0], method, maxexp=4, numpts=10, ndataperpt=1000):\n",
    "        res.append(zzz)\n",
    "        #print('{}'.format(zzz), flush=True)\n",
    "    FlassPlot.pic([ x[0] / wmax for x in res], [ x[1]['mse'] for x in res], label=name)\n",
    "FlassPlot.axeslabel('n / wmax', 'mse')\n",
    "# FlassPlot.title('synthetic epsilon-greedy: estimation error')\n",
    "#FlassPlot.savefig('epsilongreedy.mse.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
